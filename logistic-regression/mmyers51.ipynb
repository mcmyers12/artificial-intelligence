{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import math\n",
    "import sys\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 - Programming Assignment (Summer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "When we last left our agent in Module 4, it was wandering around a world filled with plains, forests, swamps, hills and mountains. This presupposes a map with known terrain:\n",
    "\n",
    "```\n",
    "......\n",
    "...**.\n",
    "...***\n",
    "..^...\n",
    "..~^..\n",
    "```\n",
    "\n",
    "but what if all we know is that we have some area of interest, that we've reduced to a GPS grid:\n",
    "\n",
    "```\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "```\n",
    "\n",
    "and the agent has to determine what kind of terrain is to the left, front and right of it?\n",
    "\n",
    "Assuming the agent has a very simple visual sensor that constructs a 4x4 grayscale image for each of the three directions, it might it could see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAF1CAYAAABhxMraAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f37f3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "For this programming assignment your tasks are:\n",
    "\n",
    "1. Write a logistic regression that simply determines if something is a hill or not (two class problem). \n",
    "2. You will also evaluate that logistic regression by generating a *confusion matrix*.\n",
    "\n",
    "For a starting point, you can refer to **module-8-pseudocode.pdf** and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d795d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRSSmgwKSU0GhaSm/wNGyg4ZgskLDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1130cf450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWZaDwsyy/g+6v0LzEKq4RgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11318f650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "4. `calculate_confusion_matrix`\n",
    "\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, a logistic regression that determines if a sensor image is hills (1) or not (0).\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes, in this case \"hills\" and \"not hills\". This means you should probably generate training data with, say, 100 hills and then 100 of all the other types of terrain combined.\n",
    "\n",
    "When you send your data to the actual `learn_model` function, it will need to have all the String labels transformed to 0 or 1 appropriately. Remember, you also need to set $x_0$ = 1.0; *where* you do that is up to you but you need to be consistent (if you do it in `generate_data` then don't also do it in `learn_model` or `apply_model`.\n",
    "\n",
    "You can make `generate_data` as sophisticated as you like. But it should at least take n and a label so that:\n",
    "\n",
    "`generate_data( clean_data, 100, \"hills\")`\n",
    "\n",
    "generates 100 hills, 100 not hills and has transformed the String labels into 1 and 0, respectively.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the logistic regression model. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "I should also mention that gradient descent is not the usual approach to linear|logistic regression because the error function actually has an *exact* solution. However, in the case of large data sets, the exact solution often fails and in any case, the use of gradient descent will prepare you for neural networks next week.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller. \n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the List of Thetas.\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes a List of Thetas (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a Tuple of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19).\n",
    "\n",
    "If the data is labeled, you will return a Tuple of the actual value (0 or 1) and the predicted value (0 or 1). In this case, you return a List of something like [(0, 1), (1, 1), (0, 0), (1, 0)].\n",
    "\n",
    "### `calculate_confusion_matrix`\n",
    "\n",
    "The `calculate_confusion_matrix` takes the results of `apply_model` when labeled=True and prints a nice HTML version of a confusion matrix and include statistics for error rate, true positive rate and true negative rate.\n",
    "\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (and not to be modifying a copy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Generate Hills**\n",
    "\n",
    "This is a helper function for the generate_data function.  Given the clean data, n, a label, and an array data_out that represents the data that will be returned by generate_data, this function generates n blurred hills using the blur function and the clean data.  It iterates through the different options for hill data to return an equal number of the different types of hills.  Each hill is added to the data_out array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_hills(data, n, label, data_out):\n",
    "    hill_index = 0\n",
    "    for i in range(n):\n",
    "        blurred_hill = blur(data[label][hill_index])\n",
    "        blurred_hill[-1] = 1.0\n",
    "        blurred_hill.insert(0, 1.0)  # Add x_0 of 1\n",
    "        data_out.append(blurred_hill)\n",
    "\n",
    "        if hill_index < 3:\n",
    "            hill_index += 1\n",
    "        else:\n",
    "            hill_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Generate Not Hills**\n",
    "\n",
    "This is a helper function for the generate_data function. Given the data n, a label, and an array data_out that represents the data that will be returned by generate_data, this function generates n blurred data points that are not hills.  It iterates through the different options for data that are not hills to return an equal number of the different types of non hill data. Each data point is added to the data_out array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_not_hills(data, n, label, data_out):\n",
    "    not_hill_data = []\n",
    "    for key in data:\n",
    "        if key != label:\n",
    "            for data_point in data[key]:\n",
    "                not_hill_data.append(data_point)\n",
    "\n",
    "    not_hill_index = 0\n",
    "    for i in range(n):\n",
    "        blurred_not_hill = blur(not_hill_data[not_hill_index])\n",
    "        blurred_not_hill[-1] = 0.0\n",
    "        blurred_not_hill.insert(0, 1.0)  # Add x_0 of 1\n",
    "        data_out.append(blurred_not_hill)\n",
    "\n",
    "        if not_hill_index < 6:\n",
    "            not_hill_index += 1\n",
    "        else:\n",
    "            not_hill_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Dot Product**\n",
    "\n",
    "This function calculates the dot product of a list of thetas and a list of xs.  The dot product of two vectors a and b is aâ‹…b = a1b1 + a2b2 + a3b3 +...+ anbn.  This is used to calculate y hat.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_product(thetas, xs):\n",
    "    z = 0\n",
    "    xs_no_y = xs[0:len(xs) - 1]\n",
    "    if len(thetas) != len(xs_no_y):\n",
    "        print '\\n\\n\\nthetas length different than xs\\n\\n\\n'\n",
    "\n",
    "    for i in range(len(thetas)):\n",
    "        z += thetas[i] * xs[i]\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate y hat**\n",
    "\n",
    "This function calculates y hat given a list of thetas and a list of xs.  The formula for y hat is:\n",
    "$$\\hat{y} = \\frac{1}{1+e^{-\\theta_0}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_yhat(thetas, xs):\n",
    "    z = dot_product(thetas, xs)\n",
    "    yhat = 1 / (1 + math.e ** (-z))\n",
    "\n",
    "    if yhat < 0 or yhat > 1:\n",
    "        print '\\n\\n\\nyhat not in range 0, 1\\n\\n\\n'\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate Error**\n",
    "\n",
    "This function calculates error using the formula for error for logistic regresstion:\n",
    "$$J(\\theta)=-\\frac{1}{n}\\sum_i\ty_i\tlog(\\hat{y_i})\t+\t(1\t- y_i)log(1\t- \\hat{y_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error(thetas, train_data):\n",
    "    error_summation = 0\n",
    "    for xs in train_data:\n",
    "        y = xs[-1]\n",
    "        yhat = calculate_yhat(thetas, xs)\n",
    "\n",
    "        if yhat == 0 and (1 - yhat) == 0:\n",
    "            pass\n",
    "\n",
    "        elif yhat == 0:\n",
    "            error_summation += ((1 - y) * math.log(1 - yhat))\n",
    "\n",
    "        elif (1 - yhat) == 0:\n",
    "            error_summation += (y * math.log(yhat))\n",
    "\n",
    "        else:\n",
    "            error_summation += (y * math.log(yhat) + (1 - y) * math.log(1 - yhat))\n",
    "\n",
    "    n = len(train_data)\n",
    "    error = - (1.0 / n) * error_summation\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Derivative**\n",
    "\n",
    "This function calculates the dertivate using the y hat function. The formula used to calculate the derivative is:\n",
    "$$\\frac{\\partial\tJ}{\\partial\t\\theta_j}\t=\t\\frac{1}{n}\\sum_i(\\hat{y_i}\t- y_i)x_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative(j, thetas, train_data):\n",
    "    derivative_summation = 0\n",
    "\n",
    "    n = len(train_data)\n",
    "\n",
    "    for xs in train_data:\n",
    "        y = xs[-1]\n",
    "        yhat = calculate_yhat(thetas, xs)\n",
    "        xij = xs[j]\n",
    "\n",
    "        derivative_summation += (yhat - y) * xij\n",
    "\n",
    "    deriv = (1.0 / n) * derivative_summation\n",
    "    return deriv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Print HTML Table**\n",
    "\n",
    "This function prints a nicely formated HTML table given a list of lists.  It is used to print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_html_table(data):\n",
    "    display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "        )\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 10 blurred \"hills\" examples with balanced (same number of) \"non hills\" examples to see that the function is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>1.0</td><td>0.102632128446</td><td>0.0740703308802</td><td>0.098461296359</td><td>0.00569742562448</td><td>0.103157705715</td><td>0.0663106372084</td><td>1.0</td><td>0.0393398040381</td><td>0.101944086186</td><td>0.866056298499</td><td>0.845682151889</td><td>0.898663824714</td><td>0.83045293177</td><td>0.85705190276</td><td>0.801491883898</td><td>0.961085602967</td><td>1.0</td></tr><tr><td>1.0</td><td>0.123882856746</td><td>0.0599161572128</td><td>0.0919985501339</td><td>0.215754419118</td><td>0.140455975273</td><td>0.957238715692</td><td>0.150152273736</td><td>0.124930302319</td><td>0.877899711566</td><td>0.725520674564</td><td>0.77072700588</td><td>0.0787832795145</td><td>0.972865731971</td><td>0.606450896032</td><td>1.0</td><td>0.862021457348</td><td>1.0</td></tr><tr><td>1.0</td><td>0.0617591490171</td><td>0.0208188034815</td><td>0.0567793162505</td><td>0.118786854234</td><td>0.771484035022</td><td>0.0155504858838</td><td>0.0538302561751</td><td>0.147263001118</td><td>0.862971159877</td><td>0.933870879154</td><td>0.182127720925</td><td>0.0962592916957</td><td>0.785431681124</td><td>0.907775935199</td><td>0.921851620288</td><td>0.0977707864959</td><td>1.0</td></tr><tr><td>1.0</td><td>0.101271443397</td><td>0.179207467786</td><td>0.164869118225</td><td>0.0887848210918</td><td>0.137420036088</td><td>0.0933247265431</td><td>0.186274794822</td><td>0.828123139834</td><td>0.14860062564</td><td>0.178225164514</td><td>0.861578472668</td><td>0.966345084226</td><td>0.157321772347</td><td>0.918111872902</td><td>0.932945930946</td><td>0.813852496343</td><td>1.0</td></tr><tr><td>1.0</td><td>0.0912487962655</td><td>0.0650982590044</td><td>0.0603268255944</td><td>0.129078049319</td><td>0.103392261864</td><td>0.103232571604</td><td>0.997248767985</td><td>0.129800590167</td><td>0.123117804014</td><td>0.76425690108</td><td>1.0</td><td>0.947077098355</td><td>1.0</td><td>1.0</td><td>0.853475706394</td><td>0.803748189056</td><td>1.0</td></tr><tr><td>1.0</td><td>0.105093697487</td><td>0.0647168592495</td><td>0.171909909792</td><td>0.132041486879</td><td>0.0947628337265</td><td>0.856580514299</td><td>0.0982664994432</td><td>0.0</td><td>1.0</td><td>0.795291126015</td><td>0.805537786431</td><td>0.157581065922</td><td>0.980272331536</td><td>1.0</td><td>0.879937208661</td><td>1.0</td><td>1.0</td></tr><tr><td>1.0</td><td>0.042991411261</td><td>0.150129094769</td><td>0.161301767748</td><td>0.156903151498</td><td>1.0</td><td>0.0258226382514</td><td>0.104386633613</td><td>0.067631732525</td><td>0.987137622248</td><td>0.879783562283</td><td>0.0506053988975</td><td>0.0905828941408</td><td>0.993696115334</td><td>0.97271411612</td><td>0.845421159762</td><td>0.0892763098265</td><td>1.0</td></tr><tr><td>1.0</td><td>0.0882114265326</td><td>0.064517879405</td><td>0.122632459451</td><td>0.018991753229</td><td>0.16037942695</td><td>0.0443752152253</td><td>0.144683346118</td><td>0.979628874245</td><td>0.120461938955</td><td>0.0711231199166</td><td>1.0</td><td>0.876723587921</td><td>0.0</td><td>0.77008971255</td><td>0.751594965144</td><td>0.90757387106</td><td>1.0</td></tr><tr><td>1.0</td><td>0.107274028929</td><td>0.04675304364</td><td>0.0396307017929</td><td>0.100355238941</td><td>0.0462366344443</td><td>0.023756989781</td><td>0.981950330928</td><td>0.229646410801</td><td>0.171778797321</td><td>0.943469223203</td><td>0.94586585727</td><td>1.0</td><td>1.0</td><td>0.777302376865</td><td>0.824550262361</td><td>0.95954153532</td><td>1.0</td></tr><tr><td>1.0</td><td>0.103735270363</td><td>0.0439257077307</td><td>0.0293180258979</td><td>0.120084914757</td><td>0.212896961729</td><td>0.937764795471</td><td>0.0499233881226</td><td>0.184497386061</td><td>0.947637757376</td><td>1.0</td><td>0.803625667251</td><td>0.0983558538537</td><td>1.0</td><td>0.800524419183</td><td>0.84122512349</td><td>1.0</td><td>1.0</td></tr><tr><td>1.0</td><td>0.16316043532</td><td>0.162903405497</td><td>0.168781390441</td><td>0.131512408878</td><td>0.0281366456292</td><td>0.160823886025</td><td>0.156578421416</td><td>0.0319856407698</td><td>0.0994816637491</td><td>0.127803957098</td><td>0.133669913539</td><td>0.141826574553</td><td>0.904597688287</td><td>0.942130821298</td><td>0.800490679253</td><td>0.825666706141</td><td>0.0</td></tr><tr><td>1.0</td><td>0.0902839153388</td><td>0.132020199601</td><td>0.0682805995504</td><td>0.0486510969028</td><td>0.1109000685</td><td>0.124269801625</td><td>0.0751745086329</td><td>0.132677653748</td><td>0.943172022279</td><td>0.167712767421</td><td>0.94736218049</td><td>0.00839667013809</td><td>0.849370038173</td><td>0.817261352065</td><td>1.0</td><td>0.942328002351</td><td>0.0</td></tr><tr><td>1.0</td><td>0.114698712729</td><td>0.181929106558</td><td>0.0924956281544</td><td>0.0798496182239</td><td>0.0820533716716</td><td>0.0215745152187</td><td>0.137958045359</td><td>0.0838475874081</td><td>0.147896143836</td><td>0.870999687479</td><td>0.120397555803</td><td>1.0</td><td>0.95028985608</td><td>0.788716521708</td><td>0.901666577897</td><td>1.0</td><td>0.0</td></tr><tr><td>1.0</td><td>0.00742785007504</td><td>0.994881178163</td><td>0.081083223366</td><td>0.034535238306</td><td>0.939175432644</td><td>0.867365280879</td><td>0.771880319632</td><td>0.149555498179</td><td>0.796351318554</td><td>1.0</td><td>0.899759969766</td><td>0.924040804877</td><td>0.163988089532</td><td>0.877607658992</td><td>0.152580460446</td><td>0.125449382312</td><td>0.0</td></tr><tr><td>1.0</td><td>0.138501848398</td><td>0.0735892119645</td><td>0.92983526432</td><td>0.117897924732</td><td>0.135944019988</td><td>0.901967004297</td><td>0.94303166151</td><td>0.938451621505</td><td>1.0</td><td>0.835391467484</td><td>0.90313768577</td><td>0.988798480013</td><td>0.178937686724</td><td>0.0948269771294</td><td>1.0</td><td>0.0601648078183</td><td>0.0</td></tr><tr><td>1.0</td><td>0.983902238574</td><td>0.145028200898</td><td>0.101616622477</td><td>0.193234987974</td><td>0.843889362696</td><td>0.691992168783</td><td>0.0645205773195</td><td>0.119733709077</td><td>0.912467578314</td><td>0.989791334462</td><td>0.743515923543</td><td>0.104816050608</td><td>0.884404847346</td><td>0.117968150267</td><td>0.146822779275</td><td>0.043816147897</td><td>0.0</td></tr><tr><td>1.0</td><td>0.164445374092</td><td>0.0205830610686</td><td>0.00958174757265</td><td>0.894758660069</td><td>0.0660911592326</td><td>0.106031804754</td><td>1.0</td><td>0.720580831131</td><td>0.0335832043937</td><td>0.782607935534</td><td>1.0</td><td>0.943995483341</td><td>0.144621478304</td><td>0.0850184172342</td><td>0.0586185615146</td><td>1.0</td><td>0.0</td></tr><tr><td>1.0</td><td>0.0207245977557</td><td>0.126878447595</td><td>0.0</td><td>0.0449155102764</td><td>0.0557677148441</td><td>0.119184334957</td><td>0.0976621214985</td><td>0.041655761525</td><td>0.00525261238921</td><td>0.0927225758529</td><td>0.11874250278</td><td>0.129648314629</td><td>0.808128544545</td><td>1.0</td><td>1.0</td><td>0.997208578604</td><td>0.0</td></tr><tr><td>1.0</td><td>0.00729401148582</td><td>0.160818081091</td><td>0.050164876453</td><td>0.00471453833703</td><td>0.0901945403262</td><td>0.0</td><td>0.0673707469913</td><td>0.114482240059</td><td>0.980404222406</td><td>0.0857843001637</td><td>0.962361196181</td><td>0.0281553808262</td><td>0.81761749629</td><td>0.92497238225</td><td>0.727807655229</td><td>0.978940245105</td><td>0.0</td></tr><tr><td>1.0</td><td>0.261709774208</td><td>0.159300888623</td><td>0.0543925937352</td><td>0.138915453714</td><td>0.128824634516</td><td>0.113521558803</td><td>0.0599625341632</td><td>0.154757963906</td><td>0.0165422165237</td><td>0.836313871047</td><td>0.140957361314</td><td>0.923330547798</td><td>0.838264752711</td><td>0.920753542819</td><td>0.879457717459</td><td>0.823709870002</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_data(data, n, label):\n",
    "    data_out = []\n",
    "    generate_hills(data, n, label, data_out)\n",
    "    generate_not_hills(data, n, label, data_out)\n",
    "\n",
    "    return data_out\n",
    "\n",
    "results = generate_data( clean_data, 10, \"hills\")\n",
    "print_html_table(results)\n",
    "#for result in results:\n",
    "#    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a logistic regression model for classifying sensor images as \"hills\" or \"not hills\". Use your `generate_data` function to generate a training set with 100 hills examples. **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def learn_model(train_data, verbose=False):\n",
    "    epsilon = 1 / 10000000.0\n",
    "    alpha = 0.1\n",
    "    m = len(train_data[0]) - 1\n",
    "    thetas = [random.uniform(-1, 1) for i in range(m)]\n",
    "    previous_error = 0.0\n",
    "    current_error = calculate_error(thetas, train_data)\n",
    "    print_counter = 0\n",
    "    while abs(current_error - previous_error) > epsilon:\n",
    "        new_thetas = [0 for i in range(m)]\n",
    "        for j in range(m): \n",
    "            new_thetas[j] = thetas[j] - alpha * derivative(j, thetas, train_data)\n",
    "        thetas = new_thetas\n",
    "\n",
    "        if verbose and print_counter % 1000 == 0:\n",
    "            print 'error: ', current_error\n",
    "            print\n",
    "\n",
    "        if current_error > previous_error:\n",
    "            alpha = alpha / 10.0\n",
    "            \n",
    "        previous_error = current_error\n",
    "        current_error = calculate_error(thetas, train_data)\n",
    "        print_counter += 1\n",
    "\n",
    "train_data = generate_data( clean_data, 100, \"hills\")\n",
    "#model = learn_model( train_data, True)\n",
    "model = [-22.400546976561237, -10.451067964042313, -18.6086749056464, -14.1214695347607, -6.36399199170839, 11.428122477078729, 3.0248446407761627, 3.4316227441828544, 12.576993255048198, -10.316226530691987, 10.761316221645709, 12.501387621641353, -9.776272973274683, 0.3172110649805399, 13.275939870295009, 12.24751308359399, -4.983004296479011]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred \"hills\" examples with balanced \"non hills\" examples and use this as your test data. Set labeled=True and generate results to use in `calculate_confusion_matrix`. Print out the first 10 results, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.9999668145231511), (1, 0.9650188894129691), (1, 0.9999997531419534), (1, 0.999111987217161), (1, 0.9992356579533592), (1, 0.9827102196150841), (1, 0.999619538452553), (1, 0.999586115999328), (1, 0.9995101447465782), (1, 0.850540432422011), (1, 0.9999626250108812), (1, 0.9995972872079366), (1, 0.9994417449490253), (1, 0.9967988388503365), (1, 0.9998367097884373), (1, 0.906674121378201), (1, 0.9999987993041294), (1, 0.9999633539465673), (1, 0.998531972183369), (1, 0.960571737482456), (1, 0.9998282303939673), (1, 0.9999967452682015), (1, 0.9998864481171907), (1, 0.95177181255487), (1, 0.9992279308522141), (1, 0.9991453386056075), (1, 0.9942546145052569), (1, 0.9999555407827536), (1, 0.9995215772137487), (1, 0.9998637668751007), (1, 0.9997426641890642), (1, 0.9998087521724053), (1, 0.9999948615214752), (1, 0.9999994976847885), (1, 0.998937954282794), (1, 0.996553145146648), (1, 0.8772877012250547), (1, 0.9764827649922994), (1, 0.9997338490184445), (1, 0.990879964828696), (1, 0.9920037931190292), (1, 0.9997858143767924), (1, 0.9999175960532201), (1, 0.9845412470818035), (1, 0.9964632241345512), (1, 0.9786390883389481), (1, 0.999918640395985), (1, 0.9606178642397983), (1, 0.9994685695536888), (1, 0.9914070261248275), (1, 0.9983012454427613), (1, 0.999112438132145), (0, 0.45692381533984494), (1, 0.9770398568396086), (1, 0.9999894363091897), (1, 0.9999111919881729), (1, 0.999974135213542), (1, 0.9988832810610346), (1, 0.9994673686368193), (1, 0.9899284927732594), (1, 0.9992905149267305), (1, 0.9978822691247337), (0, 0.28795506292468964), (1, 0.9999876962246975), (1, 0.999990366256842), (1, 0.9757579969588012), (1, 0.999888439140991), (1, 0.9986306593606741), (1, 0.9998290122191082), (1, 0.9948139823445539), (1, 0.9984772792594374), (1, 0.9990984993100183), (1, 0.9996678560776261), (1, 0.9998942503429031), (1, 0.9981186536817539), (1, 0.9781076565598117), (1, 0.9988262097130349), (1, 0.9981699595597531), (1, 0.9999235923262857), (1, 0.9940020563931037), (1, 0.9978098692603303), (1, 0.9836738767427622), (1, 0.994304526079609), (1, 0.8003761690482509), (1, 0.999961421502179), (1, 0.9995765262561616), (1, 0.9998740526449955), (1, 0.9997999311113047), (1, 0.9988682901538001), (1, 0.9995939863747744), (1, 0.9999521391947815), (1, 0.9978821486758203), (0, 0.37694059695877374), (1, 0.8315828293149132), (1, 0.9999153512517399), (1, 0.9999088752293971), (1, 0.9999620537142102), (1, 0.9995935676513124), (1, 0.9990978680517137), (1, 0.9944551982233935), (0, 0.0641634672133766), (0, 0.3287306986619396), (0, 0.00022684653584364076), (0, 2.0253441796253383e-05), (0, 0.0027551162396706776), (0, 2.963568811409651e-06), (0, 0.0009177226632812746), (0, 0.0030145881237718954), (0, 0.079322922390917), (0, 0.0001266443933296289), (0, 2.3080440011182027e-05), (0, 0.0005046020194484416), (0, 4.293895403252749e-05), (0, 0.003048632526481549), (0, 0.004696378182065656), (0, 0.0352717811724248), (0, 0.0037324783526107917), (0, 0.0012769955245747844), (0, 0.01648423195285208), (0, 0.00018345007938223187), (0, 0.0032837871412129778), (0, 0.002005327711472229), (0, 0.005492840726566966), (0, 0.0008422790462175103), (0, 8.294196796501409e-08), (0, 0.0001282314536255855), (0, 0.005590445154764008), (0, 0.0007936898020510535), (0, 0.010749346694650665), (0, 0.01466032115901472), (0, 9.257602860049834e-06), (0, 2.3392460635030698e-05), (0, 0.009642462119900342), (0, 0.0008971936940983597), (0, 0.001278124981736334), (0, 0.043892868273059556), (0, 0.08566709008403549), (0, 0.03933018383984495), (0, 2.519255708608822e-06), (0, 0.01452315478210015), (0, 0.00036190204975041927), (0, 0.014499293910575263), (0, 0.010357884378940118), (1, 0.5620305822681667), (0, 0.27172422383663053), (0, 5.828606041499882e-06), (0, 0.000503171385897739), (0, 8.507537532957327e-05), (0, 0.0023057549334981374), (0, 0.026315913278383698), (0, 0.07746563437778567), (0, 0.010289148730729404), (0, 0.0004556083844098678), (0, 2.2979295229383514e-05), (0, 0.00025076674370407877), (0, 0.0001247044925767475), (0, 4.451353028330141e-05), (0, 0.07380118907935265), (0, 0.06318367943142185), (0, 4.004337661656014e-06), (0, 0.008877468303818524), (0, 0.0019711539424373432), (0, 5.190676163021998e-05), (0, 0.0014453724765860427), (0, 0.00017675162448178256), (0, 0.0021710470655184905), (0, 2.7924215411712657e-05), (0, 0.0017602383646293815), (0, 1.8433026732392553e-05), (0, 0.00034774226961729274), (0, 0.0025093406880394077), (0, 0.18138386647249566), (0, 0.003402463815847727), (0, 0.001428428620050304), (0, 0.0232550770157708), (0, 0.0009723181177243034), (0, 0.0010299817478570592), (0, 0.00018422448427641395), (0, 0.0008305621191751546), (0, 0.005463671558902459), (0, 1.4924326385919057e-06), (0, 0.059896358760350626), (0, 2.6155244389626293e-06), (0, 0.00017341892112803574), (0, 0.00013180181718804547), (0, 0.016672128429324286), (0, 0.005484052880311723), (0, 0.00015813061562656373), (0, 0.00026210183147088974), (0, 0.0003752037365817758), (0, 0.0003369790016395482), (0, 0.026394942699297014), (0, 0.07798476334318845), (0, 0.005438932450160862), (0, 0.002866466045553366), (0, 9.926634566277559e-05), (0, 4.028121072490593e-06), (0, 0.00012986948857005254), (0, 6.766084753316869e-05), (0, 0.0004575625330030586)]\n"
     ]
    }
   ],
   "source": [
    "test_data = generate_data(clean_data, 100, \"hills\")\n",
    "\n",
    "def apply_model(model, test_data, labeled=False):\n",
    "    results = []\n",
    "    for xs in test_data:\n",
    "        yhat = calculate_yhat(model, xs)\n",
    "        predicted = None\n",
    "        if yhat < .5:\n",
    "            predicted = 0\n",
    "        else:\n",
    "            predicted = 1\n",
    "        \n",
    "        \n",
    "        if labeled:\n",
    "            actual = xs[-1]\n",
    "            results.append((actual, predicted))\n",
    "        else:\n",
    "           results.append((predicted, yhat))\n",
    "            \n",
    "    return results\n",
    "\n",
    "results = apply_model( model, test_data)\n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results above, show your confusion matrix for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  97.0\n",
      "FP:  1.0\n",
      "FN:  3.0\n",
      "TN:  99.0\n",
      "error:  2.0 %\n",
      "true_positive_rate:  97.0 %\n",
      "true_negative_rate:  99.0 %\n"
     ]
    }
   ],
   "source": [
    "def calculate_confusion_matrix(results):\n",
    "    n = len(results)\n",
    "    TP = 0.0\n",
    "    FP = 0.0\n",
    "    FN = 0.0\n",
    "    TN = 0.0\n",
    "    for result in results:\n",
    "        actual = result[0]\n",
    "        predicted = result[1]\n",
    "        if actual == predicted:\n",
    "            if actual == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        \n",
    "        else:\n",
    "            if predicted == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    \n",
    "    print \"TP: \", TP\n",
    "    print \"FP: \", FP\n",
    "    print \"FN: \", FN\n",
    "    print \"TN: \", TN\n",
    "    \n",
    "    error = (FN + FP) / n\n",
    "    print \"error: \", error * 100.0, \"%\"\n",
    "    \n",
    "    true_positive_rate = TP / (TP + FN)\n",
    "    print \"true_positive_rate: \", true_positive_rate * 100.0, \"%\"\n",
    "\n",
    "    true_negative_rate = TN / (TN + FP)\n",
    "    print \"true_negative_rate: \", true_negative_rate * 100.0, \"%\"\n",
    "\n",
    "results = apply_model( model, test_data, True)\n",
    "calculate_confusion_matrix(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
