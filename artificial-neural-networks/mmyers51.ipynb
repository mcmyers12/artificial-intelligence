{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10 - Programming Assignment (Summer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Last week we left our agent with a simple logistic regression that it could use to classify a picture from its cheap visual \"sensor\" as hills or not hills. We *could* make a logistic regression for each train type (hills/not hills, plains/not plains, swamp/not swamp, forest/not forest) and pick the one with the largest probability but that's exactly the kind of a problem a Multi-Layer Perceptron (MLP) Artificial Neural Network (ANN) was designed to solve.\n",
    "\n",
    "Here are the \"pure\" images again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAF1CAYAAABhxMraAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160b1a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "For this programming assignment your tasks are:\n",
    "\n",
    "1. Write an ANN regression that simply determines what kind of terrain it is. This is a multi-class problem.\n",
    "2. You will also evaluate your model for at least 3 different numbers of nodes in the hidden layer (2, 4, 8) and determine which one has the lowest *error rate*.\n",
    "\n",
    "For a starting point, you can refer to **module-10-pseudocode.pdf** and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As before, we have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1199d0dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRSSmgwKSU0GhaSm/wNGyg4ZgskLDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119df0690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f47c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "4. `generate_validation_curves`\n",
    "\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, an ANN that determines if a sensor image is hills, swamp, forest or plains.\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes for each class. This means you should probably generate training data with, say, 100 of each type.\n",
    "\n",
    "But what do we do about the class label with the neural network?\n",
    "\n",
    "In this case, we can do \"one hot\". Instead of `generate_data` outputing a single 0 or 1, it should output a vector of 0's and 1's so that $y$ is now a vector as well as $x$. We can use the first position for hill, the second for swamp, the third for forest and the fourth for plains:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "what am I? swamp.\n",
    "\n",
    "Unlike logistic regression, you should set the *biases* inside the neural network (the implict $x_0$ = 1) because there are going to be lot of them (one for every hidden and output node).\n",
    "\n",
    "`generate_data` now only needs to take how many you want of each class:\n",
    "\n",
    "`generate_data( clean_data, 100)`\n",
    "\n",
    "generates 100 hills, 100 swamp, 100 forest, 100 plains and transforms $y$ into the respective \"one hot\" encoding.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the ANN. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "You should add a parameter to indicate how many nodes the hidden layer should have.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller.\n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the neural network. The hidden layer will be one vector of thetas for each hidden node. And the output layer will have its own thetas, one for each output (4 in this case). Return it as a Tuple: (List of List, List of List).\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes the ANN (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a List of Tuples of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19) so you have [(0, 0.30), (1, 0.98), (0, 0.87), (0, 0.12)]. Note that unlike the logistic regression, the threshold for 1 is not 0.5 but which value is largest (0.98 in this case).\n",
    "\n",
    "If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1). For a single data point, you'll have the pairs of actual values [(0, 1), (0, 0), (0, 0), (1, 0)] is a misclassification and [(0, 0), (0, 0), (1, 1), (0, 0)] will be a correct classification. Then you have a List of *those*, one for each observation.\n",
    "\n",
    "### `generate_validation_curves`\n",
    "\n",
    "The `generate_validation_curves` is going to be a bit different than the confusion matrix version last week. It should take the information required to plot validation curves over the train and test sets for the specified parameter values.\n",
    "\n",
    "So basically, you have:\n",
    "\n",
    "1. generate training set\n",
    "2. generate test set\n",
    "3. loop over [2, 4, 8]\n",
    "    1. train model and apply to train data, calculate error rate.\n",
    "    2. apply to test data and calculae error rate.\n",
    "    3. plot both curves.\n",
    "\n",
    "The net results should be one plot of 2 curves over 3 parameter values. Please state in a markdown field afterwards which number of hidden nodes had the lowest error rate.\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (and not to be modifying a copy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Print HTML Table**\n",
    "\n",
    "This function prints a nicely formated HTML table given a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_html_table(data):\n",
    "    print_results = []\n",
    "    for row in data:\n",
    "        row_list = []\n",
    "        for x in row:\n",
    "            if type(x) == float:\n",
    "                x = round(x, 2)\n",
    "            row_list.append(x)\n",
    "        print_results.append(row_list)\n",
    "    display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in print_results)\n",
    "        )\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Generate Labeled Data**\n",
    "\n",
    "This function is used in generate_data to generate n data points of each of the different types of data.  For example, if passed n=10, label=\"hills\", and one_hot_index=0, it will generate 10 blurred hills test data examples.  This function is called 4 times, one for each of the different types of data, in the generate_data function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_labeled_data(data, n, label, one_hot_index, data_out):\n",
    "    y = [0.0, 0.0, 0.0, 0.0]\n",
    "    y[one_hot_index] = 1.0\n",
    "    loop = len(data[label]) - 1\n",
    "\n",
    "    index = 0\n",
    "    for i in range(n):\n",
    "        blurred_data = blur(data[label][index])\n",
    "        blurred_data[-1] = y  # TODO: make sure I don't need to make a deep copy of this\n",
    "        data_out.append(blurred_data)\n",
    "\n",
    "        if index < loop:\n",
    "            index += 1\n",
    "        else:\n",
    "            index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Initialize Network**\n",
    "\n",
    "This function initializes the neural network given the test data, a number of hidden nodes, and a number of output nodes.  It determines the number of thetas for the hidden nodes and output nodes, then sets random values between 0 and 1 for each of the thetas of the hidden nodes and output nodes.  The network is represented as a dictionary, with two keys: 'hidden_node_thetas' and 'output_node_thetas' that each point to a list of lists of thetas. Throughout the execution of this program, various key value pairs get added to the dictionary to represent the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_network(data, num_hidden_nodes, num_output_nodes):\n",
    "    num_hidden_node_thetas = len(data[0])\n",
    "    num_output_node_thetas = num_hidden_nodes + 1\n",
    "    network = {'hidden_node_thetas': [], 'output_node_thetas': []}\n",
    "\n",
    "    for i in range(num_hidden_nodes):\n",
    "        hidden_node_thetas = [random.uniform(0, 1) for x in range(num_hidden_node_thetas)]\n",
    "        network['hidden_node_thetas'].append(hidden_node_thetas)\n",
    "\n",
    "    for i in range(num_output_nodes):\n",
    "        output_node_thetas = [random.uniform(0, 1) for x in range(num_output_node_thetas)]\n",
    "        network['output_node_thetas'].append(output_node_thetas)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Dot Product**\n",
    "\n",
    "This function calculates the dot product of a list of thetas and a list of xs.  The dot product of two vectors a and b is a⋅b = a1b1 + a2b2 + a3b3 +...+ anbn.  This is used to calculate y hat.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_product(thetas, xs):\n",
    "    z = 0.0\n",
    "\n",
    "    for i in range(len(thetas)):\n",
    "        z += thetas[i] * xs[i]\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate y hat**\n",
    "\n",
    "This function calculates y hat given a list of thetas and a list of xs.  The formula for y hat is:\n",
    "$$\\hat{y} = \\frac{1}{1+e^{-\\theta_0}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_yhat(thetas, xs):\n",
    "    z = dot_product(thetas, xs)\n",
    "    yhat = 1.0 / (1.0 + math.e ** (-z))\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Add Bias**\n",
    "\n",
    "Given a list, this function adds a bias (1) to the front of the list.  This is used to add biases to the hidden nodes and output nodes in the execution of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bias(xs):\n",
    "    xs_with_bias = copy.deepcopy(xs)\n",
    "    xs_with_bias.insert(0, 1.0)\n",
    "\n",
    "    return xs_with_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate Hidden Node Outputs**\n",
    "\n",
    "Given the network and a set of input nodes, this function calculates the output of each of the hidden nodes.  The list of outputs is returned and then stored in the network dictionary with key 'hidden_node_outputs'.  First, a bias is added to the input node list, then for each set of hidden node thetas, yhat is calculated with those thetas and the input nodes with bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_hidden_node_outputs(network, input_nodes):\n",
    "    hidden_node_outputs = []\n",
    "    input_nodes_with_bias = add_bias(input_nodes[:len(input_nodes) - 1])\n",
    "\n",
    "    for hidden_node_thetas in network['hidden_node_thetas']:\n",
    "        hidden_node_output = calculate_yhat(hidden_node_thetas, input_nodes_with_bias)\n",
    "        hidden_node_outputs.append(hidden_node_output)\n",
    "\n",
    "    return hidden_node_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate Output Node Outputs**\n",
    "\n",
    "Given the network, this function calculates the output of each of the output nodes.  The list of outputs is returned and then stored in the network dictionary with key 'output_node_outputs'. First, a bias is added to the list of hidden node outputs, then for each set of output node thetas, yhat is calculated with those thetas and the hidden nodes with bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_output_node_outputs(network):\n",
    "    output_node_outputs = []\n",
    "    hidden_node_outputs_with_bias = add_bias(network['hidden_node_outputs'])\n",
    "\n",
    "    for output_node_thetas in network['output_node_thetas']:\n",
    "        output_node_output = calculate_yhat(output_node_thetas, hidden_node_outputs_with_bias)\n",
    "        output_node_outputs.append(output_node_output)\n",
    "\n",
    "    return output_node_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate Delta-O**\n",
    "\n",
    "Given y and yhat, this function calculates delta_o using the formula yhat \\* (1.0 - yhat) \\* (y - yhat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_o(y, yhat):\n",
    "    delta_o = yhat * (1.0 - yhat) * (y - yhat)\n",
    "\n",
    "    return delta_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Calculate Delta-Os**\n",
    "\n",
    "Given a network and a set of ys (the actual values of the current point in the data set) in form ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_os(network, ys):\n",
    "    delta_os = []\n",
    "\n",
    "    for i in range(len(ys)):\n",
    "        yhat = network['output_node_outputs'][i]\n",
    "        y = ys[i]\n",
    "\n",
    "        delta_o = calculate_delta_o(y, yhat)\n",
    "        delta_os.append(delta_o)\n",
    "\n",
    "    return delta_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_h(yhat, thetas, delta_os):\n",
    "    delta_h = yhat * (1 - yhat)\n",
    "\n",
    "    summation = 0.0\n",
    "    for i in range(len(thetas)):\n",
    "        theta = thetas[i]\n",
    "        delta_o = delta_os[i]\n",
    "        summation += (theta * delta_o)\n",
    "\n",
    "    delta_h = delta_h * summation\n",
    "\n",
    "    return delta_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_hs(network):\n",
    "    delta_hs = []\n",
    "    delta_os = network['delta_os']\n",
    "\n",
    "    for i in range(len(network['hidden_node_thetas'])):\n",
    "        thetas = []\n",
    "        for output_node_thetas in network['output_node_thetas']:\n",
    "            thetas.append(\n",
    "                output_node_thetas[i + 1])  # Get the  first theta of each output node for the first hidden node,\n",
    "            #   2nd of each output node for the second hidden node, etc.\n",
    "            # i + 1 because we skip the theta for the bbias\n",
    "\n",
    "        yhat = network['hidden_node_outputs'][i]  # TODO double check this is the right yhat but i'm pretty sure it is....\n",
    "        delta_h = calculate_delta_h(yhat, thetas, delta_os)\n",
    "        delta_hs.append(delta_h)\n",
    "\n",
    "    return delta_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_output_node_thetas(network, alpha):\n",
    "    for i in range(len(network['output_node_thetas'])):\n",
    "        thetas = network['output_node_thetas'][i]\n",
    "        delta_o = network['delta_os'][i]\n",
    "\n",
    "        hidden_node_outputs_with_bias = add_bias(network['hidden_node_outputs'])\n",
    "        for j in range(len(thetas)):\n",
    "            hidden_node_y = hidden_node_outputs_with_bias[j]\n",
    "            thetas[j] = thetas[j] + alpha * delta_o * hidden_node_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_hidden_node_thetas(network, alpha, input_nodes):\n",
    "    input_nodes_with_bias = add_bias(input_nodes[:len(input_nodes) - 1])  # use only input node xs, without the y\n",
    "\n",
    "    for i in range(len(network['hidden_node_thetas'])):\n",
    "        thetas = network['hidden_node_thetas'][i]\n",
    "        delta_h = network['delta_hs'][i]\n",
    "\n",
    "        for j in range(len(thetas)):\n",
    "            xi = input_nodes_with_bias[j]\n",
    "            thetas[j] = thetas[j] + alpha * delta_h * xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_individual_error(ys, yhats):\n",
    "    error_summation = 0\n",
    "    for i in range(len(ys)):\n",
    "        y = ys[i]\n",
    "        yhat = yhats[i]\n",
    "\n",
    "        if yhat == 0 and (1 - yhat) == 0:\n",
    "            pass\n",
    "\n",
    "        elif yhat == 0:\n",
    "            error_summation += ((1 - y) * math.log(1 - yhat))\n",
    "\n",
    "        elif (1 - yhat) == 0:\n",
    "            error_summation += (y * math.log(yhat))\n",
    "\n",
    "        else:\n",
    "            error_summation += (y * math.log(yhat) + (1 - y) * math.log(1 - yhat))\n",
    "\n",
    "    return error_summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error(data, network, alpha):\n",
    "    error = 0\n",
    "    test_network = {}\n",
    "    test_network['hidden_node_thetas'] = copy.deepcopy(network['hidden_node_thetas'])\n",
    "    test_network['output_node_thetas'] = copy.deepcopy(network['output_node_thetas'])\n",
    "\n",
    "    for input_nodes in data:\n",
    "        test_network['hidden_node_outputs'] = calculate_hidden_node_outputs(network, input_nodes)\n",
    "        test_network['output_node_outputs'] = calculate_output_node_outputs(network)\n",
    "\n",
    "        ys = input_nodes[-1]\n",
    "        yhats = test_network['output_node_outputs']\n",
    "        \n",
    "        error += calculate_individual_error(ys, yhats)\n",
    "            \n",
    "        test_network['delta_os'] = calculate_delta_os(network, ys)\n",
    "        test_network['delta_hs'] = calculate_delta_hs(test_network)  # TODO check this\n",
    "\n",
    "        update_output_node_thetas(test_network, alpha)\n",
    "        update_hidden_node_thetas(test_network, alpha, input_nodes)\n",
    "\n",
    "    return -1/(error / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labeled_data_results(actuals, predictions):\n",
    "    result = []\n",
    "    max_prediction_index = predictions.index(max(predictions))\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        actual = actuals[i]\n",
    "        if i != max_prediction_index:\n",
    "            prediction = 0.0\n",
    "            result.append((actual, prediction))\n",
    "\n",
    "        else:\n",
    "            prediction = 1.0\n",
    "            result.append((actual, prediction))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unlabeled_data_results(predictions):\n",
    "    result = []\n",
    "    max_prediction_index = predictions.index(max(predictions))\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        prediction = predictions[i]\n",
    "        if i != max_prediction_index:\n",
    "            result.append((0, 1 - prediction))\n",
    "\n",
    "        else:\n",
    "            result.append((1, prediction))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_validation_curve_error(results):\n",
    "    n = 0.0\n",
    "    errors = 0.0\n",
    "    not_errors = 0.0\n",
    "    for result in results:\n",
    "        for point in results:\n",
    "            error = False\n",
    "            for pair in point:\n",
    "                if pair[0] != pair[1]:\n",
    "                    error = True\n",
    "            if error:\n",
    "                errors += 1.0\n",
    "\n",
    "            else:\n",
    "                not_errors += 1.0\n",
    "            n += 1.0\n",
    "    print 'errors', errors\n",
    "    print 'not_errors', not_errors\n",
    "    print\n",
    "    print\n",
    "    error_rate = errors / n\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 10 blurred \"hills\" examples with balanced (same number of) \"non hills\" examples to see that the function is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>0.11</td><td>0.13</td><td>0.08</td><td>0.0</td><td>0.04</td><td>0.07</td><td>0.88</td><td>0.16</td><td>0.11</td><td>0.9</td><td>0.97</td><td>0.8</td><td>0.8</td><td>0.81</td><td>1.0</td><td>0.86</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.12</td><td>0.08</td><td>0.11</td><td>0.01</td><td>0.07</td><td>0.74</td><td>0.12</td><td>0.13</td><td>0.8</td><td>1.0</td><td>0.94</td><td>0.1</td><td>0.96</td><td>1.0</td><td>0.75</td><td>0.78</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.12</td><td>0.09</td><td>0.07</td><td>0.12</td><td>0.75</td><td>0.04</td><td>0.08</td><td>0.18</td><td>0.85</td><td>0.97</td><td>0.07</td><td>0.16</td><td>0.92</td><td>0.94</td><td>1.0</td><td>0.0</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.05</td><td>0.11</td><td>0.14</td><td>0.22</td><td>0.13</td><td>0.09</td><td>0.14</td><td>0.91</td><td>0.1</td><td>0.08</td><td>0.82</td><td>0.68</td><td>0.12</td><td>0.84</td><td>1.0</td><td>1.0</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.08</td><td>0.12</td><td>0.09</td><td>0.06</td><td>0.07</td><td>0.19</td><td>0.82</td><td>0.08</td><td>0.14</td><td>0.76</td><td>0.88</td><td>0.8</td><td>0.61</td><td>0.88</td><td>0.86</td><td>0.91</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.08</td><td>0.11</td><td>0.02</td><td>0.1</td><td>0.04</td><td>0.81</td><td>0.17</td><td>0.05</td><td>0.76</td><td>1.0</td><td>0.88</td><td>0.02</td><td>0.91</td><td>0.95</td><td>1.0</td><td>0.84</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.08</td><td>0.1</td><td>0.05</td><td>0.07</td><td>1.0</td><td>0.09</td><td>0.05</td><td>0.06</td><td>0.91</td><td>1.0</td><td>0.18</td><td>0.05</td><td>0.91</td><td>1.0</td><td>0.92</td><td>0.07</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.1</td><td>0.09</td><td>0.05</td><td>0.05</td><td>0.05</td><td>0.0</td><td>0.04</td><td>0.97</td><td>0.17</td><td>0.04</td><td>0.75</td><td>1.0</td><td>0.11</td><td>1.0</td><td>0.8</td><td>0.95</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.09</td><td>0.08</td><td>0.17</td><td>0.14</td><td>0.13</td><td>0.02</td><td>0.99</td><td>0.13</td><td>0.14</td><td>0.88</td><td>0.88</td><td>0.86</td><td>0.9</td><td>0.97</td><td>0.9</td><td>1.0</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.17</td><td>0.08</td><td>0.14</td><td>0.11</td><td>0.03</td><td>0.78</td><td>0.04</td><td>0.07</td><td>0.93</td><td>0.8</td><td>0.98</td><td>0.0</td><td>0.92</td><td>1.0</td><td>0.88</td><td>0.79</td><td>[1.0, 0.0, 0.0, 0.0]</td></tr><tr><td>0.12</td><td>0.14</td><td>0.14</td><td>0.05</td><td>0.19</td><td>0.11</td><td>0.19</td><td>0.02</td><td>0.94</td><td>0.18</td><td>0.9</td><td>0.17</td><td>0.93</td><td>0.96</td><td>0.91</td><td>0.9</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.07</td><td>0.05</td><td>0.23</td><td>0.11</td><td>0.07</td><td>0.04</td><td>0.14</td><td>0.06</td><td>0.1</td><td>1.0</td><td>0.1</td><td>0.67</td><td>0.78</td><td>0.94</td><td>0.93</td><td>0.92</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.17</td><td>0.06</td><td>0.11</td><td>0.05</td><td>0.12</td><td>0.14</td><td>0.01</td><td>0.21</td><td>0.8</td><td>0.06</td><td>0.76</td><td>0.16</td><td>0.66</td><td>0.98</td><td>0.92</td><td>0.92</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.09</td><td>0.16</td><td>0.19</td><td>0.16</td><td>0.17</td><td>0.16</td><td>0.04</td><td>0.1</td><td>0.11</td><td>0.98</td><td>0.1</td><td>0.89</td><td>0.81</td><td>1.0</td><td>0.89</td><td>0.85</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.06</td><td>0.08</td><td>0.1</td><td>0.1</td><td>0.12</td><td>0.13</td><td>0.04</td><td>0.02</td><td>0.92</td><td>0.1</td><td>0.89</td><td>0.1</td><td>1.0</td><td>0.92</td><td>0.89</td><td>1.0</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.08</td><td>0.06</td><td>0.12</td><td>0.08</td><td>0.02</td><td>0.06</td><td>0.1</td><td>0.12</td><td>0.13</td><td>0.88</td><td>0.08</td><td>0.88</td><td>0.98</td><td>0.83</td><td>1.0</td><td>0.89</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.17</td><td>0.03</td><td>0.1</td><td>0.17</td><td>0.05</td><td>0.09</td><td>0.11</td><td>0.04</td><td>0.99</td><td>0.09</td><td>1.0</td><td>0.08</td><td>0.84</td><td>1.0</td><td>0.85</td><td>1.0</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.03</td><td>0.07</td><td>0.07</td><td>0.2</td><td>0.11</td><td>0.14</td><td>0.13</td><td>0.11</td><td>0.12</td><td>0.74</td><td>0.18</td><td>1.0</td><td>0.9</td><td>0.89</td><td>0.82</td><td>0.76</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.05</td><td>0.04</td><td>0.18</td><td>0.08</td><td>0.05</td><td>0.16</td><td>0.07</td><td>0.0</td><td>0.89</td><td>0.08</td><td>0.84</td><td>0.18</td><td>0.86</td><td>0.81</td><td>0.88</td><td>0.96</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.02</td><td>0.14</td><td>0.13</td><td>0.1</td><td>0.06</td><td>0.05</td><td>0.18</td><td>0.14</td><td>0.13</td><td>1.0</td><td>0.08</td><td>0.99</td><td>0.81</td><td>0.85</td><td>1.0</td><td>0.93</td><td>[0.0, 1.0, 0.0, 0.0]</td></tr><tr><td>0.05</td><td>1.0</td><td>0.09</td><td>0.13</td><td>0.76</td><td>0.99</td><td>1.0</td><td>0.1</td><td>0.95</td><td>1.0</td><td>0.9</td><td>1.0</td><td>0.12</td><td>0.83</td><td>0.07</td><td>0.09</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.19</td><td>0.11</td><td>0.79</td><td>0.09</td><td>0.12</td><td>0.93</td><td>0.94</td><td>0.87</td><td>0.89</td><td>0.9</td><td>0.88</td><td>0.74</td><td>0.02</td><td>0.1</td><td>0.99</td><td>0.17</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.9</td><td>0.13</td><td>0.17</td><td>0.22</td><td>0.84</td><td>0.82</td><td>0.0</td><td>0.08</td><td>0.88</td><td>0.9</td><td>1.0</td><td>0.2</td><td>0.82</td><td>0.09</td><td>0.13</td><td>0.09</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.18</td><td>0.1</td><td>0.1</td><td>0.98</td><td>0.09</td><td>0.13</td><td>0.67</td><td>0.87</td><td>0.07</td><td>0.74</td><td>1.0</td><td>0.73</td><td>0.06</td><td>0.19</td><td>0.1</td><td>0.81</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.07</td><td>1.0</td><td>0.11</td><td>0.19</td><td>0.98</td><td>0.91</td><td>0.93</td><td>0.03</td><td>0.87</td><td>0.96</td><td>0.97</td><td>0.98</td><td>0.06</td><td>1.0</td><td>0.09</td><td>0.1</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.07</td><td>0.18</td><td>0.72</td><td>0.1</td><td>0.05</td><td>0.76</td><td>0.94</td><td>0.91</td><td>1.0</td><td>0.91</td><td>0.94</td><td>0.72</td><td>0.18</td><td>0.17</td><td>1.0</td><td>0.14</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.81</td><td>0.12</td><td>0.12</td><td>0.05</td><td>0.89</td><td>0.94</td><td>0.03</td><td>0.07</td><td>0.77</td><td>0.93</td><td>0.89</td><td>0.07</td><td>0.84</td><td>0.1</td><td>0.05</td><td>0.06</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.13</td><td>0.08</td><td>0.06</td><td>0.78</td><td>0.16</td><td>0.05</td><td>0.87</td><td>0.86</td><td>0.08</td><td>0.83</td><td>0.77</td><td>0.76</td><td>0.14</td><td>0.15</td><td>0.04</td><td>0.78</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.02</td><td>0.76</td><td>0.04</td><td>0.05</td><td>1.0</td><td>0.84</td><td>1.0</td><td>0.07</td><td>0.85</td><td>0.99</td><td>0.93</td><td>0.99</td><td>0.09</td><td>1.0</td><td>0.17</td><td>0.1</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.08</td><td>0.05</td><td>0.81</td><td>0.08</td><td>0.14</td><td>0.83</td><td>1.0</td><td>0.98</td><td>0.91</td><td>0.86</td><td>0.99</td><td>0.8</td><td>0.1</td><td>0.16</td><td>0.91</td><td>0.09</td><td>[0.0, 0.0, 1.0, 0.0]</td></tr><tr><td>0.13</td><td>0.11</td><td>0.09</td><td>0.12</td><td>0.09</td><td>0.06</td><td>0.07</td><td>0.05</td><td>0.18</td><td>0.12</td><td>0.14</td><td>0.08</td><td>0.99</td><td>0.92</td><td>1.0</td><td>0.9</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.14</td><td>0.15</td><td>0.09</td><td>0.09</td><td>0.07</td><td>0.02</td><td>0.03</td><td>0.02</td><td>0.0</td><td>0.06</td><td>0.06</td><td>0.07</td><td>0.82</td><td>0.99</td><td>0.92</td><td>1.0</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.09</td><td>0.0</td><td>0.13</td><td>0.13</td><td>0.07</td><td>0.15</td><td>0.17</td><td>0.06</td><td>0.04</td><td>0.06</td><td>0.07</td><td>0.19</td><td>0.99</td><td>0.8</td><td>0.82</td><td>0.96</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.05</td><td>0.08</td><td>0.09</td><td>0.0</td><td>0.1</td><td>0.16</td><td>0.1</td><td>0.12</td><td>0.21</td><td>0.07</td><td>0.09</td><td>0.08</td><td>0.87</td><td>0.79</td><td>1.0</td><td>0.84</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.18</td><td>0.11</td><td>0.13</td><td>0.14</td><td>0.09</td><td>0.09</td><td>0.1</td><td>0.0</td><td>0.06</td><td>0.08</td><td>0.12</td><td>0.08</td><td>0.91</td><td>0.89</td><td>0.86</td><td>0.96</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.09</td><td>0.15</td><td>0.12</td><td>0.03</td><td>0.14</td><td>0.09</td><td>0.07</td><td>0.04</td><td>0.18</td><td>0.12</td><td>0.07</td><td>0.09</td><td>0.81</td><td>0.87</td><td>0.88</td><td>0.9</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.08</td><td>0.06</td><td>0.16</td><td>0.14</td><td>0.02</td><td>0.09</td><td>0.08</td><td>0.0</td><td>0.16</td><td>0.04</td><td>0.06</td><td>0.2</td><td>0.9</td><td>0.95</td><td>0.93</td><td>0.79</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.05</td><td>0.08</td><td>0.18</td><td>0.0</td><td>0.18</td><td>0.08</td><td>0.02</td><td>0.11</td><td>0.11</td><td>0.12</td><td>0.1</td><td>0.16</td><td>0.77</td><td>1.0</td><td>0.92</td><td>0.86</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.09</td><td>0.15</td><td>0.06</td><td>0.19</td><td>0.01</td><td>0.18</td><td>0.03</td><td>0.1</td><td>0.07</td><td>0.11</td><td>0.12</td><td>0.13</td><td>0.81</td><td>1.0</td><td>0.94</td><td>0.9</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr><tr><td>0.11</td><td>0.0</td><td>0.15</td><td>0.12</td><td>0.08</td><td>0.14</td><td>0.12</td><td>0.08</td><td>0.11</td><td>0.11</td><td>0.23</td><td>0.16</td><td>0.98</td><td>0.96</td><td>0.88</td><td>0.94</td><td>[0.0, 0.0, 0.0, 1.0]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_data(data, n):\n",
    "    data_out = []\n",
    "\n",
    "    generate_labeled_data(data, n, \"hills\", 0, data_out)\n",
    "    generate_labeled_data(data, n, \"swamp\", 1, data_out)\n",
    "    generate_labeled_data(data, n, \"forest\", 2, data_out)\n",
    "    generate_labeled_data(data, n, \"plains\", 3, data_out)\n",
    "\n",
    "    return data_out\n",
    "\n",
    "results = generate_data( clean_data, 10)\n",
    "print_html_table(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a ANN model for classifying sensor images as hills, swamps, plains or forest. Use your `generate_data` function to generate a training set with 100 examples for each. **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.176421507978\n",
      "error:  0.12550238036\n"
     ]
    }
   ],
   "source": [
    "def learn_model(data, num_hidden_nodes, verbose=False):\n",
    "    num_output_nodes = 4\n",
    "    network = initialize_network(data, num_hidden_nodes, num_output_nodes)\n",
    "    epsilon = 0.0000001\n",
    "    alpha = 0.01 \n",
    "    \n",
    "    previous_error = 0.0\n",
    "    current_error = float('-inf')\n",
    "\n",
    "    iter = 0\n",
    "\n",
    "    while iter < 5000 and abs(current_error - previous_error) > epsilon:\n",
    "        iter += 1\n",
    "        for input_nodes in data:\n",
    "            # feed forward step\n",
    "            # calculate output of every node in the network (yhat function)\n",
    "            network['hidden_node_outputs'] = calculate_hidden_node_outputs(network, input_nodes)\n",
    "            network['output_node_outputs'] = calculate_output_node_outputs(network)\n",
    "\n",
    "            # back prop step\n",
    "            # calculate delta_o for every output node\n",
    "            ys = input_nodes[-1]\n",
    "            network['delta_os'] = calculate_delta_os(network, ys)\n",
    "\n",
    "            # calculate delta_h for every hidden node\n",
    "            network['delta_hs'] = calculate_delta_hs(network)  # TODO check this\n",
    "\n",
    "            # update all of the thetas\n",
    "            update_output_node_thetas(network, alpha)\n",
    "            update_hidden_node_thetas(network, alpha, input_nodes)\n",
    "\n",
    "        if verbose and iter % 1000 == 0:\n",
    "            print 'error: ', current_error\n",
    "\n",
    "        previous_error = current_error\n",
    "\n",
    "        current_error = calculate_error(data, network, alpha)\n",
    "\n",
    "    return (network['hidden_node_thetas'], network['output_node_thetas'])\n",
    "\n",
    "train_data = generate_data( clean_data, 100)\n",
    "model = learn_model( train_data, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each terrain and use this as your test data. Print out the first 10 results, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>(1, 0.6164337437937628)</td><td>(0, 0.9675510711578743)</td><td>(0, 0.842131505286632)</td><td>(0, 0.9999855804348053)</td></tr><tr><td>(1, 0.7038604049169829)</td><td>(0, 0.8832546970831308)</td><td>(0, 0.9563467825449917)</td><td>(0, 0.9999758581428265)</td></tr><tr><td>(1, 0.8086373197157692)</td><td>(0, 0.6828261384346177)</td><td>(0, 0.9853180310746379)</td><td>(0, 0.9999700566999509)</td></tr><tr><td>(1, 0.7426037457364486)</td><td>(0, 0.8527376534062293)</td><td>(0, 0.9632926393410058)</td><td>(0, 0.9999767758787843)</td></tr><tr><td>(1, 0.8173135628271712)</td><td>(0, 0.687017780372003)</td><td>(0, 0.9842615169088075)</td><td>(0, 0.9999723999085173)</td></tr><tr><td>(1, 0.8080408154624857)</td><td>(0, 0.7107596683398789)</td><td>(0, 0.9827529955582243)</td><td>(0, 0.9999726302611628)</td></tr><tr><td>(1, 0.6898050920291722)</td><td>(0, 0.9107000869046309)</td><td>(0, 0.9407114813856273)</td><td>(0, 0.9999788921992823)</td></tr><tr><td>(1, 0.7482606525456447)</td><td>(0, 0.7389346466264071)</td><td>(0, 0.9844113694967455)</td><td>(0, 0.999962631615603)</td></tr><tr><td>(1, 0.7410098445926516)</td><td>(0, 0.8795954271619684)</td><td>(0, 0.9517185526678941)</td><td>(0, 0.9999801306219912)</td></tr><tr><td>(1, 0.7121534055059454)</td><td>(0, 0.923125162228475)</td><td>(0, 0.922169032264561)</td><td>(0, 0.9999834456871561)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = generate_data( clean_data, 100)\n",
    "\n",
    "def apply_model(model, test_data, labeled=False):\n",
    "    network = {}\n",
    "    results = []\n",
    "    network['hidden_node_thetas'] = model[0]\n",
    "    network['output_node_thetas'] = model[1]\n",
    "\n",
    "    for input_nodes in test_data:\n",
    "        network['hidden_node_outputs'] = calculate_hidden_node_outputs(network, input_nodes)\n",
    "        network['output_node_outputs'] = calculate_output_node_outputs(network)\n",
    "\n",
    "        if labeled:\n",
    "            actuals = input_nodes[-1]\n",
    "            predictions = network['output_node_outputs']\n",
    "            result = get_labeled_data_results(actuals, predictions)\n",
    "            results.append(result)\n",
    "\n",
    "        else:\n",
    "            predictions = network['output_node_outputs']\n",
    "            result = get_unlabeled_data_results(predictions)\n",
    "            results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = apply_model( model, test_data)\n",
    "print_html_table(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're pretty sure your algorithm works (the error rate during training is going down, and you can evaluate `apply_model` results for its error rate, learn validation curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_curves(clean_data):\n",
    "    train = generate_data(clean_data, 100)\n",
    "    test = generate_data(clean_data, 100)\n",
    "    train_error_values = []\n",
    "    test_error_values = []\n",
    "    hidden_nodes = [2, 4, 8]\n",
    "    for n in hidden_nodes:\n",
    "        model = learn_model(train, n)  # verbose is False now please!\n",
    "        train_results = apply_model(model, train, True)\n",
    "        test_results = apply_model(model, test, True)\n",
    "\n",
    "        train_error_values.append(calculate_validation_curve_error(train_results))\n",
    "        test_error_values.append(calculate_validation_curve_error(test_results))\n",
    "\n",
    "    print   'hidden_nodes', hidden_nodes\n",
    "    print   'train_error_values', train_error_values\n",
    "    print 'test_error_values', test_error_values\n",
    "\n",
    "    plt.plot(hidden_nodes, train_error_values)\n",
    "    plt.plot(hidden_nodes, test_error_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which number of hidden nodes is best? **8**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
