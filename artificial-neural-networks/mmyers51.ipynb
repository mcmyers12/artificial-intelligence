{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10 - Programming Assignment (Summer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Last week we left our agent with a simple logistic regression that it could use to classify a picture from its cheap visual \"sensor\" as hills or not hills. We *could* make a logistic regression for each train type (hills/not hills, plains/not plains, swamp/not swamp, forest/not forest) and pick the one with the largest probability but that's exactly the kind of a problem a Multi-Layer Perceptron (MLP) Artificial Neural Network (ANN) was designed to solve.\n",
    "\n",
    "Here are the \"pure\" images again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAF1CAYAAABhxMraAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d14a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "For this programming assignment your tasks are:\n",
    "\n",
    "1. Write an ANN regression that simply determines what kind of terrain it is. This is a multi-class problem.\n",
    "2. You will also evaluate your model for at least 3 different numbers of nodes in the hidden layer (2, 4, 8) and determine which one has the lowest *error rate*.\n",
    "\n",
    "For a starting point, you can refer to **module-10-pseudocode.pdf** and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As before, we have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b635d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGRSSmgwKSU0GhaSm/wNGyg4ZgskLDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b986710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEICAYAAACnA7rCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bbb3c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "4. `generate_validation_curves`\n",
    "\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, an ANN that determines if a sensor image is hills, swamp, forest or plains.\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes for each class. This means you should probably generate training data with, say, 100 of each type.\n",
    "\n",
    "But what do we do about the class label with the neural network?\n",
    "\n",
    "In this case, we can do \"one hot\". Instead of `generate_data` outputing a single 0 or 1, it should output a vector of 0's and 1's so that $y$ is now a vector as well as $x$. We can use the first position for hill, the second for swamp, the third for forest and the fourth for plains:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "what am I? swamp.\n",
    "\n",
    "Unlike logistic regression, you should set the *biases* inside the neural network (the implict $x_0$ = 1) because there are going to be lot of them (one for every hidden and output node).\n",
    "\n",
    "`generate_data` now only needs to take how many you want of each class:\n",
    "\n",
    "`generate_data( clean_data, 100)`\n",
    "\n",
    "generates 100 hills, 100 swamp, 100 forest, 100 plains and transforms $y$ into the respective \"one hot\" encoding.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the ANN. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "You should add a parameter to indicate how many nodes the hidden layer should have.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller.\n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the neural network. The hidden layer will be one vector of thetas for each hidden node. And the output layer will have its own thetas, one for each output (4 in this case). Return it as a Tuple: (List of List, List of List).\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes the ANN (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a List of Tuples of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19) so you have [(0, 0.30), (1, 0.98), (0, 0.87), (0, 0.12)]. Note that unlike the logistic regression, the threshold for 1 is not 0.5 but which value is largest (0.98 in this case).\n",
    "\n",
    "If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1). For a single data point, you'll have the pairs of actual values [(0, 1), (0, 0), (0, 0), (1, 0)] is a misclassification and [(0, 0), (0, 0), (1, 1), (0, 0)] will be a correct classification. Then you have a List of *those*, one for each observation.\n",
    "\n",
    "### `generate_validation_curves`\n",
    "\n",
    "The `generate_validation_curves` is going to be a bit different than the confusion matrix version last week. It should take the information required to plot validation curves over the train and test sets for the specified parameter values.\n",
    "\n",
    "So basically, you have:\n",
    "\n",
    "1. generate training set\n",
    "2. generate test set\n",
    "3. loop over [2, 4, 8]\n",
    "    1. train model and apply to train data, calculate error rate.\n",
    "    2. apply to test data and calculae error rate.\n",
    "    3. plot both curves.\n",
    "\n",
    "The net results should be one plot of 2 curves over 3 parameter values. Please state in a markdown field afterwards which number of hidden nodes had the lowest error rate.\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (and not to be modifying a copy)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Print HTML Table**\n",
    "\n",
    "This function prints a nicely formated HTML table given a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_html_table(data):\n",
    "    print_results = []\n",
    "    for row in data:\n",
    "        row_list = []\n",
    "        for x in row:\n",
    "            if type(x) == float:\n",
    "                x = round(x, 2)\n",
    "            row_list.append(x)\n",
    "        print_results.append(row_list)\n",
    "    display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in print_results)\n",
    "        )\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_labeled_data(data, n, label, one_hot_index, data_out):\n",
    "    y = [0.0, 0.0, 0.0, 0.0]\n",
    "    y[one_hot_index] = 1.0\n",
    "    loop = len(data[label]) - 1\n",
    "\n",
    "    index = 0\n",
    "    for i in range(n):\n",
    "        blurred_data = blur(data[label][index])\n",
    "        blurred_data[-1] = y  # TODO: make sure I don't need to make a deep copy of this\n",
    "        data_out.append(blurred_data)\n",
    "\n",
    "        if index < loop:\n",
    "            index += 1\n",
    "        else:\n",
    "            index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_network(data, num_hidden_nodes, num_output_nodes):\n",
    "    num_hidden_node_thetas = len(data[0])\n",
    "    num_output_node_thetas = num_hidden_nodes + 1  # num hidden noes + 1 because of bias\n",
    "    network = {'hidden_node_thetas': [], 'output_node_thetas': []}\n",
    "\n",
    "    for i in range(num_hidden_nodes):\n",
    "        hidden_node_thetas = [random.uniform(0, 1) for x in range(num_hidden_node_thetas)]\n",
    "        network['hidden_node_thetas'].append(hidden_node_thetas)\n",
    "\n",
    "    for i in range(num_output_nodes):\n",
    "        output_node_thetas = [random.uniform(0, 1) for x in range(num_output_node_thetas)]\n",
    "        network['output_node_thetas'].append(output_node_thetas)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_product(thetas, xs):\n",
    "    z = 0.0\n",
    "\n",
    "    for i in range(len(thetas)):\n",
    "        z += thetas[i] * xs[i]\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_yhat(thetas, xs):\n",
    "    z = dot_product(thetas, xs)\n",
    "    yhat = 1.0 / (1.0 + math.e ** (-z))\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bias(xs):\n",
    "    xs_with_bias = copy.deepcopy(xs)  # todo see if this is needed\n",
    "    xs_with_bias.insert(0, 1.0)\n",
    "\n",
    "    return xs_with_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_hidden_node_outputs(network, input_nodes):\n",
    "    hidden_node_outputs = []\n",
    "    input_nodes_with_bias = add_bias(input_nodes[:len(input_nodes) - 1])  # use only input node xs, without the y\n",
    "\n",
    "    for hidden_node_thetas in network['hidden_node_thetas']:\n",
    "        hidden_node_output = calculate_yhat(hidden_node_thetas, input_nodes_with_bias)\n",
    "        hidden_node_outputs.append(hidden_node_output)\n",
    "\n",
    "    return hidden_node_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_output_node_outputs(network):\n",
    "    output_node_outputs = []\n",
    "    hidden_node_outputs_with_bias = add_bias(network['hidden_node_outputs'])\n",
    "\n",
    "    for output_node_thetas in network['output_node_thetas']:\n",
    "        output_node_output = calculate_yhat(output_node_thetas, hidden_node_outputs_with_bias)\n",
    "        output_node_outputs.append(output_node_output)\n",
    "\n",
    "    return output_node_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_o(y, yhat):\n",
    "    delta_o = yhat * (1.0 - yhat) * (y - yhat)\n",
    "\n",
    "    return delta_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_os(network, ys):\n",
    "    delta_os = []\n",
    "\n",
    "    for i in range(len(ys)):\n",
    "        yhat = network['output_node_outputs'][i]\n",
    "        y = ys[i]\n",
    "\n",
    "        delta_o = calculate_delta_o(y, yhat)\n",
    "        delta_os.append(delta_o)\n",
    "\n",
    "    return delta_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_h(yhat, thetas, delta_os):\n",
    "    delta_h = yhat * (1 - yhat)\n",
    "\n",
    "    summation = 0.0\n",
    "    for i in range(len(thetas)):\n",
    "        theta = thetas[i]\n",
    "        delta_o = delta_os[i]\n",
    "        summation += (theta * delta_o)\n",
    "\n",
    "    delta_h = delta_h * summation\n",
    "\n",
    "    return delta_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delta_hs(network):\n",
    "    delta_hs = []\n",
    "    delta_os = network['delta_os']\n",
    "\n",
    "    for i in range(len(network['hidden_node_thetas'])):\n",
    "        thetas = []\n",
    "        for output_node_thetas in network['output_node_thetas']:\n",
    "            thetas.append(\n",
    "                output_node_thetas[i + 1])  # Get the  first theta of each output node for the first hidden node,\n",
    "            #   2nd of each output node for the second hidden node, etc.\n",
    "            # i + 1 because we skip the theta for the bbias\n",
    "\n",
    "        yhat = network['hidden_node_outputs'][i]  # TODO double check this is the right yhat but i'm pretty sure it is....\n",
    "        delta_h = calculate_delta_h(yhat, thetas, delta_os)\n",
    "        delta_hs.append(delta_h)\n",
    "\n",
    "    return delta_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_output_node_thetas(network, alpha):\n",
    "    for i in range(len(network['output_node_thetas'])):\n",
    "        thetas = network['output_node_thetas'][i]\n",
    "        delta_o = network['delta_os'][i]\n",
    "\n",
    "        hidden_node_outputs_with_bias = add_bias(network['hidden_node_outputs'])\n",
    "        for j in range(len(thetas)):\n",
    "            hidden_node_y = hidden_node_outputs_with_bias[j]\n",
    "            thetas[j] = thetas[j] + alpha * delta_o * hidden_node_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_hidden_node_thetas(network, alpha, input_nodes):\n",
    "    input_nodes_with_bias = add_bias(input_nodes[:len(input_nodes) - 1])  # use only input node xs, without the y\n",
    "\n",
    "    for i in range(len(network['hidden_node_thetas'])):\n",
    "        thetas = network['hidden_node_thetas'][i]\n",
    "        delta_h = network['delta_hs'][i]\n",
    "\n",
    "        for j in range(len(thetas)):\n",
    "            xi = input_nodes_with_bias[j]\n",
    "            thetas[j] = thetas[j] + alpha * delta_h * xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_individual_error(ys, yhats):\n",
    "    error_summation = 0\n",
    "    for i in range(len(ys)):\n",
    "        y = ys[i]\n",
    "        yhat = yhats[i]\n",
    "\n",
    "        if yhat == 0 and (1 - yhat) == 0:\n",
    "            pass\n",
    "\n",
    "        elif yhat == 0:\n",
    "            error_summation += ((1 - y) * math.log(1 - yhat))\n",
    "\n",
    "        elif (1 - yhat) == 0:\n",
    "            error_summation += (y * math.log(yhat))\n",
    "\n",
    "        else:\n",
    "            error_summation += (y * math.log(yhat) + (1 - y) * math.log(1 - yhat))\n",
    "\n",
    "    return error_summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error(data, network, alpha):\n",
    "    error = 0\n",
    "    test_network = {}\n",
    "    test_network['hidden_node_thetas'] = copy.deepcopy(network['hidden_node_thetas'])\n",
    "    test_network['output_node_thetas'] = copy.deepcopy(network['output_node_thetas'])\n",
    "\n",
    "    for input_nodes in data:\n",
    "        test_network['hidden_node_outputs'] = calculate_hidden_node_outputs(network, input_nodes)\n",
    "        test_network['output_node_outputs'] = calculate_output_node_outputs(network)\n",
    "\n",
    "        ys = input_nodes[-1]\n",
    "        yhats = test_network['output_node_outputs']\n",
    "        \n",
    "        error += calculate_individual_error(ys, yhats)\n",
    "            \n",
    "        test_network['delta_os'] = calculate_delta_os(network, ys)\n",
    "        test_network['delta_hs'] = calculate_delta_hs(test_network)  # TODO check this\n",
    "\n",
    "        update_output_node_thetas(test_network, alpha)\n",
    "        update_hidden_node_thetas(test_network, alpha, input_nodes)\n",
    "\n",
    "    return -1/(error / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labeled_data_results(actuals, predictions):\n",
    "    result = []\n",
    "    max_prediction_index = predictions.index(max(predictions))\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        actual = actuals[i]\n",
    "        if i != max_prediction_index:\n",
    "            prediction = 0.0\n",
    "            result.append((actual, prediction))\n",
    "\n",
    "        else:\n",
    "            prediction = 1.0\n",
    "            result.append((actual, prediction))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unlabeled_data_results(predictions):\n",
    "    result = []\n",
    "    max_prediction_index = predictions.index(max(predictions))\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        prediction = predictions[i]\n",
    "        if i != max_prediction_index:\n",
    "            result.append((0, 1 - prediction))\n",
    "\n",
    "        else:\n",
    "            result.append((1, prediction))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_validation_curve_error(results):\n",
    "    n = 0.0\n",
    "    errors = 0.0\n",
    "    not_errors = 0.0\n",
    "    for result in results:\n",
    "        for point in results:\n",
    "            error = False\n",
    "            for pair in point:\n",
    "                if pair[0] != pair[1]:\n",
    "                    error = True\n",
    "            if error:\n",
    "                errors += 1.0\n",
    "\n",
    "            else:\n",
    "                not_errors += 1.0\n",
    "            n += 1.0\n",
    "    print 'errors', errors\n",
    "    print 'not_errors', not_errors\n",
    "    print\n",
    "    print\n",
    "    error_rate = errors / n\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 10 blurred \"hills\" examples with balanced (same number of) \"non hills\" examples to see that the function is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0632845070846394, 0.07239171549185419, 0.1630097498064499, 0.07194067491950593, 0.03996334470467401, 0.0182974439332612, 0.9018336158474474, 0.04512641112563143, 0.10680597905021633, 0.8124042034855965, 1.0, 0.7589008078398339, 0.8504975440509045, 0.7530213286806733, 0.8286336668082284, 0.9036680786830809, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.2115781308809777, 0.16930850798638986, 0.06929884402352063, 0.16954545292615775, 0.08240251710859128, 0.6715276400612397, 0.09232781045778035, 0.044245812526653175, 1.0, 0.6550612256730948, 0.8444289522487897, 0.13074765290287813, 1.0, 0.8465097194481339, 0.8521308737865771, 0.8430101366918603, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.1124393909745981, 0.013111309093515808, 0.01615947569575457, 0.08158159034998895, 0.7344435735201722, 0.1660487067349279, 0.16927134339796315, 0.1721990305957759, 1.0, 0.8637954917610764, 0.07142998232850169, 0.050041703383193845, 0.9086646724381287, 0.9255659117399784, 0.7692417832387163, 0.07973493512323411, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.1211098880566237, 0.13907227424664317, 0.025765508992872263, 0.17333854011995511, 0.016715625974189782, 0.07583685913606893, 0.14406352339536949, 0.709591136253869, 0.09141724671164643, 0.08576679998477933, 0.8477549349992501, 0.9652976018341186, 0.104595760214556, 0.9782855029638059, 1.0, 0.779386367774423, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.035842750384977445, 0.14951584878896199, 0.07633800411818017, 0.09366715388013823, 0.08655802819108209, 0.07333426696570758, 0.685844958535808, 0.029866336789100764, 0.16376248253406456, 0.9686643057720373, 0.9988140884196554, 1.0, 0.8773147386349298, 0.7292090380681541, 0.904059772255169, 0.9431564410313519, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.06957397866074282, 0.1077672274397334, 0.0811959270534118, 0.13212569729059634, 0.13520583301105024, 0.7909522531151609, 0.050479049648240376, 0.08601709777229544, 0.8497774391968923, 0.92571634982051, 0.9206473913686066, 0.14695591937698022, 0.7430871008050572, 0.9152312253626963, 0.8317455416497183, 0.8154313896521257, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.11893261823905732, 0.11529290491309861, 0.11671527327613568, 0.2151361601874997, 0.9193040957924049, 0.11128514213441663, 0.2173329845636226, 0.03214921547280504, 0.7498415213574131, 0.9299550478671056, 0.03789911448913541, 0.17977534038497925, 0.9946681238411195, 0.8747252315993804, 0.6927885790453449, 0.09746505682675334, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.09802400028536189, 0.140911256121035, 0.05733987117472771, 0.07207269250483252, 0.05772875626510214, 0.0970115819836499, 0.0, 0.8875489445514166, 0.004568412187993268, 0.09269771261303793, 0.9284585912007951, 0.765919636475933, 0.12739111942388492, 0.9778537251751195, 0.9055423632696644, 0.9510541364223839, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.12149056974294223, 0.0, 0.09809666333018276, 0.11797072304783122, 0.22355220895436073, 0.12224839416161722, 0.8301623747448287, 0.128223856618379, 0.05024804479692954, 0.8144232612258336, 0.915862300930355, 1.0, 1.0, 0.802563469178989, 0.9657079681897054, 0.7169102434875945, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.15524038080434738, 0.1823716955306144, 0.029040826193231173, 0.08716192172027054, 0.20628470801574492, 0.977493790539968, 0.13096201906276725, 0.10955135142273949, 0.9544728044678057, 0.6436785938626766, 0.8664791063784625, 0.13505793098144162, 0.8922305381909604, 0.8599431521788967, 0.776109328407963, 0.9264730505245137, [1.0, 0.0, 0.0, 0.0]]\n",
      "[0.08565373626169946, 0.213534232221895, 0.14063403632104352, 0.115014003514814, 0.027292274514440856, 0.07390727572305728, 0.15503604383973568, 0.1826221823736186, 0.8838406462606725, 0.11924085564682188, 0.9879712669308822, 0.09697954595899483, 0.8301092436393581, 0.8693309506763109, 0.9125613002792441, 0.8355292716208822, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.08255608506356517, 0.01948338693179308, 0.01677601571247757, 0.13822049446608137, 0.09013621339145392, 0.16952957593511375, 0.10130868904207248, 0.10747067127229806, 0.08514155353443932, 0.9069516998885688, 0.12008635242725665, 0.9906353982533049, 0.8234612942133774, 1.0, 0.8967417465478988, 1.0, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.046582813300637405, 0.07395627727177741, 0.13302910736135629, 0.16028206126329808, 0.1772143919045666, 0.04751355236490976, 0.08026027089673114, 0.15011116665390317, 0.973259303214383, 0.2055431722064468, 0.982419846799082, 0.045116522638537805, 0.7958972601630374, 0.90256429938711, 0.996556303135463, 0.8894402813449898, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.08140677270742325, 0.13121406076032371, 0.0, 0.15363980113664996, 0.12862867762225863, 0.09743361050209076, 0.12972074258530708, 0.16400454721262026, 0.09545624964646529, 0.840611942733499, 0.10081846484971822, 0.8609168114700227, 0.9250419480266526, 0.7711623073364907, 0.9398620998269559, 0.9188681849912022, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.017174181915201953, 0.07408324239326715, 0.07637612377999471, 0.15095688066454216, 0.14196819597102828, 0.060687183891486245, 0.07677581333956181, 0.06991488386975869, 0.9024750392891954, 0.025304147953894185, 0.8205686746686252, 0.04394953134823374, 0.9976818567634087, 0.8367735760029499, 0.8537494514711338, 0.771249523370376, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.11594439659263499, 0.07033254696952719, 0.10868754436169067, 0.09633752588475789, 0.06096817135912298, 0.03773104071011171, 0.07875717584245247, 0.12458034112549903, 0.09930718001656208, 0.924435290427275, 0.13368740089212344, 0.8694805786143224, 0.9128695024118925, 0.9034925398786536, 0.9108449244010711, 1.0, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.010334596404382876, 0.09719100641194495, 0.08559780421087179, 0.02698703400536724, 0.14119304598099425, 0.09956928349944957, 0.1636414549709852, 0.04857724307057011, 0.8687110198127791, 0.10135666665705483, 0.877523786545629, 0.15561756590833048, 0.9034438776876653, 1.0, 0.9024807637969855, 0.8824763255120739, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.08603522595171766, 0.04895234009398807, 0.08152429580700046, 0.10896830797801522, 0.02436264337859459, 0.06399434660575642, 0.0, 0.11304874791200688, 0.18912113838612396, 0.8648054204798364, 0.08274062834000398, 0.8720671447457831, 0.9703117700707463, 0.9191640902584529, 0.7193695761616341, 0.8416347499318697, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.14765109824966519, 0.12072257357854857, 0.0898637790571075, 0.09616265204684962, 0.05723018971254817, 0.0, 0.18544983117362165, 0.09718923229199661, 0.9945480790820944, 0.02485250986015912, 0.8283996687451041, 0.09764126863586492, 0.9811604265638907, 1.0, 0.7615864667130219, 0.8107589957340925, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.04739184923171154, 0.08792149176699308, 0.16097523617300777, 0.14399016220513303, 0.04313457024147049, 0.11181147951278264, 0.17604036095087144, 0.12180364992057552, 0.08444372772846688, 0.903298356559609, 0.11057552253770314, 0.9074849960441682, 0.7923163609676371, 0.9181470684625951, 0.8424600169209161, 0.9583834195943832, [0.0, 1.0, 0.0, 0.0]]\n",
      "[0.004778378794180277, 0.9639788451882947, 0.14033948422995227, 0.1322407883835899, 0.6787261908847594, 0.944970070493661, 0.8144734270650685, 0.08711056354119942, 0.9477079597872533, 0.8442792898362008, 0.8396047119222778, 0.8197055688953211, 0.10799506675443621, 0.8692168439739937, 0.1209893662471297, 0.07559180659465418, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.06547977774871686, 0.154057799079072, 0.9386557585846231, 0.10202174219678808, 0.1960987436683101, 0.9512637960837863, 0.944467859968583, 0.808621642675182, 0.853606237771583, 1.0, 1.0, 1.0, 0.09929605569862135, 0.11985424649836249, 0.9182406191527359, 0.16762210301748712, [0.0, 0.0, 1.0, 0.0]]\n",
      "[1.0, 0.0, 0.08997236243145414, 0.06026555810301141, 0.9018934962089767, 0.8335326678890149, 0.09748657857724623, 0.08609810229513057, 0.928991892359328, 0.9020114265955131, 0.9831958428032307, 0.16068290647404082, 0.770652526556326, 0.16765434936579351, 0.04209635757063233, 0.11845139411848515, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.08193205212134437, 0.12289129867519005, 0.1478464086323607, 0.9267448651415671, 0.055811649835321636, 0.13048727738629468, 1.0, 0.8663031286554377, 0.018295717622042032, 0.8057608878541823, 1.0, 0.9093945619633544, 0.09218461999015747, 0.06302904103959799, 0.08584433762834132, 0.9125556563866706, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.006433339222102014, 0.6486184924576608, 0.12377887220238146, 0.09286098079346912, 0.9385701156484142, 0.9715836276983644, 0.834682468099185, 0.09801212531545349, 0.5158495162836, 0.9004569268026786, 0.7997327121384484, 0.7873045351156092, 0.13225203634605254, 0.9076616182895444, 0.048961743457730245, 0.08984789711539938, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.09227652397426608, 0.13554518375981955, 0.9317591097894248, 0.06377276989225408, 0.09990538427869153, 0.928631156862291, 0.9457043007247663, 0.9905065001838205, 0.8609383919596029, 0.8185991575137712, 0.8250991777186836, 0.9446527880126471, 0.02509971683866659, 0.12682951480128818, 0.8271764957807948, 0.07827974927282227, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.878199194640213, 0.06543001949820601, 0.0, 0.03915968284735987, 0.9802488525710128, 0.7832502366990537, 0.0004347237788410313, 0.11613284432109199, 0.7925095310126511, 1.0, 0.9574781585508377, 0.02654167942084988, 1.0, 0.1619972862347816, 0.06660723010993759, 0.09167609417408858, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.07962470737477248, 0.09006322031094054, 0.08027062929966437, 0.8860225753088145, 0.06890083954908177, 0.0, 0.9172282299475338, 0.8895547809306773, 0.07847293110193307, 0.7643285297111794, 0.9361812107031005, 0.8983393679871314, 0.09037125998144055, 0.07365177838238923, 0.14969623814260685, 0.9484310865761917, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.10799615975667239, 0.9599562700701691, 0.0434932084743655, 0.19349501514700407, 0.917416318105, 0.9340260288584855, 0.9426121152994971, 0.0913345732475297, 1.0, 1.0, 0.9219391293980981, 0.678069785581755, 0.11607298610029418, 0.9461769778090184, 0.08852798083927832, 0.1553901343364431, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.14450075453630823, 0.13596428977238298, 0.7871758528991877, 0.0975696030694822, 0.10580184267792184, 1.0, 1.0, 0.8291705436235037, 0.9613059401050308, 0.731670461509684, 0.7456577501214439, 0.8718539450369213, 0.08300805245070983, 0.12907744017852615, 0.9140935015018128, 0.17823559213231585, [0.0, 0.0, 1.0, 0.0]]\n",
      "[0.062693573718392, 0.19947148038831045, 0.06819651053431536, 0.07094654364942746, 0.18043830232949448, 0.15576634317668628, 0.14792932461957375, 0.10866657210492238, 0.13657716550482907, 0.15124484616420947, 0.06736624882620101, 0.10742543944452312, 1.0, 0.9215083005658669, 1.0, 0.958901487318787, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.11734940771137564, 0.09032276208776757, 0.09471073216824205, 0.11600950812200507, 0.16560318151908043, 0.0908525501512096, 0.11205218073104214, 0.08286084313285873, 0.0005676870137220763, 0.052238509193327856, 0.16668471275321944, 0.168213975952763, 0.9339228481641955, 0.8505174361422246, 1.0, 0.8787424268896843, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.0787744314503537, 0.1281001662678407, 0.060268144714729105, 0.05411696316733641, 0.14333675476451324, 0.039493062890766595, 0.07694355644054345, 0.0, 0.06247366276100695, 0.06018467447052528, 0.09944455535336785, 0.11244227108007677, 0.7804336618741089, 0.7055459246866095, 0.9380853959672607, 0.9772262859797959, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.10350345674772143, 0.01657115811201529, 0.12272707679502158, 0.03643652344670062, 0.047569758807454836, 0.07631545442382248, 0.18896070348862046, 0.10099394617291459, 0.05498449396379175, 0.12051699065884564, 0.1296442168461705, 0.017772476200932863, 0.7404720632459046, 1.0, 0.8258080231182995, 0.9126144452035689, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.15474366042520252, 0.11350015685465242, 0.04950829871091551, 0.09689904188421783, 0.07617754218766168, 0.1086911337369809, 0.12378360176653405, 0.014728088983462048, 0.15644459628445048, 0.10769458007834412, 0.12182926665670452, 0.07382013798672149, 0.963252319642231, 1.0, 1.0, 0.8770349318190312, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.14378163433593683, 0.02660092975979933, 0.05140032979723413, 0.12114004021723462, 0.11430480925291767, 0.0923325532994165, 0.04373868824764156, 0.1345885840856746, 0.0, 0.05908617171606575, 0.0552085094241638, 0.13254446008348436, 0.7931446283111505, 1.0, 0.7940056046299364, 0.8207122353764931, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.16348682085902322, 0.07573330910911091, 0.08688268141810912, 0.1437618800072583, 0.1149321964454386, 0.15270881793136756, 0.12089476524704501, 0.11880573092913094, 0.1786026409937838, 0.0324811501749402, 0.10460589551737431, 0.05693225782546147, 0.9873818827412286, 1.0, 0.8619832489954491, 1.0, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.13501862125503278, 0.07425286234820494, 0.12965981946514976, 0.05751140404075206, 0.20785863329290136, 0.09564108578898092, 0.0, 0.11439928806770001, 0.14048178612432147, 0.028462016512847854, 0.14867244446724953, 0.06092782741597141, 0.8637684317491606, 0.6838262897115301, 0.8454680784566851, 0.9574993598778684, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.15272524959708167, 0.10956096147927846, 0.07378117223680515, 0.1966437179722391, 0.057644767642349826, 0.1573758791345931, 0.06795429645842474, 0.12178289293630878, 0.1586064246512644, 0.14823057381084676, 0.07400184967815308, 0.0890535118884596, 1.0, 1.0, 1.0, 0.9746426288330412, [0.0, 0.0, 0.0, 1.0]]\n",
      "[0.0487523832254757, 0.16639123573406256, 0.1439614305471655, 0.07348298392495958, 0.07780555982153275, 0.12618590717123937, 0.06968881461003808, 0.014747307792836756, 0.08475372895020918, 0.10930540866239657, 0.09365132989531325, 0.07284010266392725, 1.0, 0.7248881354774802, 0.8129017721961977, 0.7742955889011178, [0.0, 0.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "def generate_data(data, n):\n",
    "    data_out = []\n",
    "\n",
    "    generate_labeled_data(data, n, \"hills\", 0, data_out)\n",
    "    generate_labeled_data(data, n, \"swamp\", 1, data_out)\n",
    "    generate_labeled_data(data, n, \"forest\", 2, data_out)\n",
    "    generate_labeled_data(data, n, \"plains\", 3, data_out)\n",
    "\n",
    "    return data_out\n",
    "\n",
    "results = generate_data( clean_data, 10)\n",
    "for result in results:\n",
    "    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a ANN model for classifying sensor images as hills, swamps, plains or forest. Use your `generate_data` function to generate a training set with 100 examples for each. **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def learn_model(data, num_hidden_nodes, verbose=False):\n",
    "    num_output_nodes = 4\n",
    "    network = initialize_network(data, num_hidden_nodes, num_output_nodes)\n",
    "    epsilon = 0.0000001\n",
    "    alpha = 0.01 \n",
    "    \n",
    "    previous_error = 0.0\n",
    "    current_error = float('-inf')\n",
    "\n",
    "    iter = 0\n",
    "\n",
    "    while iter < 5000 and abs(current_error - previous_error) > epsilon:\n",
    "        iter += 1\n",
    "        for input_nodes in data:\n",
    "            # feed forward step\n",
    "            # calculate output of every node in the network (yhat function)\n",
    "            network['hidden_node_outputs'] = calculate_hidden_node_outputs(network, input_nodes)\n",
    "            network['output_node_outputs'] = calculate_output_node_outputs(network)\n",
    "\n",
    "            # back prop step\n",
    "            # calculate delta_o for every output node\n",
    "            ys = input_nodes[-1]\n",
    "            network['delta_os'] = calculate_delta_os(network, ys)\n",
    "\n",
    "            # calculate delta_h for every hidden node\n",
    "            network['delta_hs'] = calculate_delta_hs(network)  # TODO check this\n",
    "\n",
    "            # update all of the thetas\n",
    "            update_output_node_thetas(network, alpha)\n",
    "            update_hidden_node_thetas(network, alpha, input_nodes)\n",
    "\n",
    "        if verbose and iter % 1000 == 0:\n",
    "            print 'error: ', current_error\n",
    "\n",
    "        previous_error = current_error\n",
    "\n",
    "        current_error = calculate_error(data, network, alpha)\n",
    "\n",
    "    return (network['hidden_node_thetas'], network['output_node_thetas'])\n",
    "\n",
    "train_data = generate_data( clean_data, 100)\n",
    "model = learn_model( train_data, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each terrain and use this as your test data. Print out the first 10 results, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = generate_data( clean_data, 100)\n",
    "\n",
    "def apply_model(model, test_data, labeled=False):\n",
    "    network = {}\n",
    "    results = []\n",
    "    network['hidden_node_thetas'] = model[0]\n",
    "    network['output_node_thetas'] = model[1]\n",
    "\n",
    "    for input_nodes in test_data:\n",
    "        network['hidden_node_outputs'] = calculate_hidden_node_outputs(network, input_nodes)\n",
    "        network['output_node_outputs'] = calculate_output_node_outputs(network)\n",
    "\n",
    "        if labeled:\n",
    "            actuals = input_nodes[-1]\n",
    "            predictions = network['output_node_outputs']\n",
    "            result = get_labeled_data_results(actuals, predictions)\n",
    "            results.append(result)\n",
    "\n",
    "        else:\n",
    "            predictions = network['output_node_outputs']\n",
    "            result = get_unlabeled_data_results(predictions)\n",
    "            results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = apply_model( model, test_data)\n",
    "print_html_table(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're pretty sure your algorithm works (the error rate during training is going down, and you can evaluate `apply_model` results for its error rate, learn validation curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_curves(clean_data):\n",
    "    train = generate_data(clean_data, 100)\n",
    "    test = generate_data(clean_data, 100)\n",
    "    train_error_values = []\n",
    "    test_error_values = []\n",
    "    hidden_nodes = [2, 4, 8]\n",
    "    for n in hidden_nodes:\n",
    "        model = learn_model(train, n)  # verbose is False now please!\n",
    "        train_results = apply_model(model, train, True)\n",
    "        test_results = apply_model(model, test, True)\n",
    "\n",
    "        train_error_values.append(calculate_validation_curve_error(train_results))\n",
    "        test_error_values.append(calculate_validation_curve_error(test_results))\n",
    "\n",
    "    print   'hidden_nodes', hidden_nodes\n",
    "    print   'train_error_values', train_error_values\n",
    "    print 'test_error_values', test_error_values\n",
    "\n",
    "    plt.plot(hidden_nodes, train_error_values)\n",
    "    plt.plot(hidden_nodes, test_error_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which number of hidden nodes is best? **8**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
