{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 - Programming Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "In this assignment you will be using the mushroom data from the Decision Tree module:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "The assignment is to write a program that will learn and apply a Naive Bayes Classifier for this problem. You'll first need to calculate all of the necessary probabilities (don't forget to use +1 smoothing) using a `learn` function. You'll then need to have a `classify` function that takes your probabilities, a List of instances (possibly a list of 1) and returns a List of Tuples. Each Tuple is a class and the *normalized* probability of that class. The List should be sorted so that the probabilities are in descending order. For example,\n",
    "\n",
    "```\n",
    "[(\"e\", 0.98), (\"p\", 0.02)]\n",
    "```\n",
    "\n",
    "when calculating the error rate of your classifier, you should pick the class with the highest probability (the first one in the list).\n",
    "\n",
    "As a reminder, the Naive Bayes Classifier generates the un-normalized probabilities from the numerator of Bayes Rule:\n",
    "\n",
    "$$P(C|A) \\propto P(A|C)P(C)$$\n",
    "\n",
    "where C is the class and A are the attributes (data). Since the normalizer of Bayes Rule is the *sum* of all possible numerators and you have to calculate them all, the normalizer is just the sum of the probabilities.\n",
    "\n",
    "You'll also need an `evaluate` function as before. You should use the $error\\_rate$ again.\n",
    "\n",
    "Use the same testing procedure as last time, on two randomized subsets of the data:\n",
    "\n",
    "1. learn the probabilities for set 1\n",
    "2. classify set 2\n",
    "3. evaluate the predictions\n",
    "4. learn the probabilities for set 2\n",
    "5. classify set 1\n",
    "6. evalute the the predictions\n",
    "7. average the classification error.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        table = list(reader)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_train_test_sets(data):\n",
    "    random.shuffle(data)\n",
    "    split_point = len(data) / 2\n",
    "    test_set = data[:split_point]\n",
    "    train_set = data[split_point:]\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_class_label_counts(data):\n",
    "    p_count = 1.0\n",
    "    e_count = 1.0\n",
    "    for row in data:\n",
    "        if row[0] == 'p':\n",
    "            p_count += 1.0\n",
    "        elif row[0] == 'e':\n",
    "            e_count += 1.0\n",
    "    \n",
    "    return p_count, e_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_probability_counts(data):\n",
    "    probability_counts = {}\n",
    "    \n",
    "    for i in range(len(data[0]) - 1):\n",
    "        i = i + 1\n",
    "        probability_counts[i] = {}\n",
    "    \n",
    "    for row in data:\n",
    "        for i in range(len(row) - 1):\n",
    "            i = i + 1\n",
    "            attribute_value = row[i]\n",
    "            if attribute_value not in probability_counts[i]:\n",
    "                probability_counts[i][attribute_value] = {'p': 1.0, 'e': 1.0} #+1 smoothing\n",
    "            else:\n",
    "                if row[0] == 'p':\n",
    "                    probability_counts[i][attribute_value]['p'] += 1.0\n",
    "                elif row[0] == 'e':\n",
    "                    probability_counts[i][attribute_value]['e'] += 1.0\n",
    "                \n",
    "    return probability_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_class_probabilities(p_count, e_count):\n",
    "    class_probabilities = { 'p' : {}, 'e' : {} }\n",
    "    p_count = p_count - 1.0\n",
    "    e_count = e_count - 1.0\n",
    "    total = p_count + e_count\n",
    "    \n",
    "    class_probabilities['p']['probability'] = p_count / total\n",
    "    class_probabilities['e']['probability'] = e_count / total\n",
    "    class_probabilities['p']['count'] = p_count \n",
    "    class_probabilities['e']['count'] = e_count \n",
    "    \n",
    "    return class_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_probability(probabilities, instance, label, class_probabilities):\n",
    "    probability = 1\n",
    "    for attribute_index in range(len(instance) - 1):\n",
    "        attribute_index += 1                                #skip class label\n",
    "        attribute_value = instance[attribute_index]\n",
    "        \n",
    "        if attribute_value in probabilities[attribute_index]:\n",
    "            probability *= probabilities[attribute_index][attribute_value][label]\n",
    "        \n",
    "        else:\n",
    "            probability *= 1 / class_probabilities[label]['count']  #If some combination wasn't in the training data, do +1 smoothing\n",
    "        \n",
    "    probability *= class_probabilities[label]['probability']\n",
    "    \n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(results):\n",
    "    denominator = results['p'] + results['e']\n",
    "    \n",
    "    results['p'] /= denominator\n",
    "    results['e'] /= denominator\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_instance(probabilities, instance, class_probabilities):\n",
    "    results = {}\n",
    "    \n",
    "    results['p'] = calculate_probability(probabilities, instance, 'p', class_probabilities)\n",
    "    results['e'] = calculate_probability(probabilities, instance, 'e', class_probabilities)\n",
    "    \n",
    "    results = normalize(results)\n",
    "    if results['p'] > results['e']:\n",
    "        return [('p', results['p']), ('e', results['e'])]\n",
    "    else:\n",
    "        return [('e', results['e']), ('p', results['p'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn(data):\n",
    "    probabilities = get_probability_counts(data)\n",
    "    p_count, e_count = get_class_label_counts(data)\n",
    "    \n",
    "    for attribute_index in probabilities:\n",
    "        for attribute_value in probabilities[attribute_index]:\n",
    "            probabilities[attribute_index][attribute_value]['p'] = probabilities[attribute_index][attribute_value]['p'] / p_count\n",
    "            probabilities[attribute_index][attribute_value]['e'] = probabilities[attribute_index][attribute_value]['e'] / e_count\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Returns a list of tuples: each is a class and the normalized probability of that class\n",
    "#sorted in descending order\n",
    "#[(\"e\", 0.98), (\"p\", 0.02)]\n",
    "def classify(probabilities, instances):\n",
    "    classifications = []\n",
    "    p_count, e_count = get_class_label_counts(data)\n",
    "    class_probabilities = get_class_probabilities(p_count, e_count)\n",
    "\n",
    "    for instance in instances:\n",
    "        classifications.append(classify_instance(probabilities, instance, class_probabilities))\n",
    "    \n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**x**\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Uses the error rate    \n",
    "def evaluate(data, classifications):\n",
    "    errors = 0.0\n",
    "    for i in range(len(data)):\n",
    "        if classifications[i][0][0] != data[i][0]:\n",
    "            errors += 1\n",
    "    \n",
    "    error_rate = errors / len(data)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Put your main function calls here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_csv('agaricus-lepiota.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set1, set2 = create_train_test_sets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = learn(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = classify(probabilities, set2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate 1:  0.0544066962088\n"
     ]
    }
   ],
   "source": [
    "error_rate1 = evaluate(set2, classifications)\n",
    "print 'error rate 1: ', error_rate1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = learn(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = classify(probabilities, set1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_rate2 = evaluate(set1, classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate 2:  0.0519448547514\n"
     ]
    }
   ],
   "source": [
    "print 'error rate 2: ', error_rate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0531757754801\n"
     ]
    }
   ],
   "source": [
    "print (error_rate1 + error_rate2) / 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
